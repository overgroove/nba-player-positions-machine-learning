{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from pandas import DataFrame\n",
    "import pandas as pd\n",
    "import scipy as sp\n",
    "from sklearn import metrics\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn import linear_model\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.feature_selection import VarianceThreshold"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reading data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def read_data(folder, name1, name2, name3):\n",
    "    loc = \"%s/%s.txt\" %(folder, name1)\n",
    "    train_set = pd.read_csv(loc, sep=\"\\t\")\n",
    "    print \"Training set has %s rows and %s coumns\" %(train_set.shape[0], train_set.shape[1])\n",
    "    loc = \"%s/%s.txt\" %(folder, name2)\n",
    "    test_set = pd.read_csv(loc, sep=\"\\t\")\n",
    "    print \"Testing set has %s rows and %s coumns\" %(test_set.shape[0], test_set.shape[1])\n",
    "    loc = \"%s/%s.txt\" %(folder, name3)\n",
    "    val_set = pd.read_csv(loc, sep=\"\\t\")\n",
    "    print \"Validation set has %s rows and %s coumns\" %(val_set.shape[0], val_set.shape[1])\n",
    "    return train_set, test_set, val_set\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set has 428 rows and 25 coumns\n",
      "Testing set has 142 rows and 25 coumns\n",
      "Validation set has 142 rows and 25 coumns\n"
     ]
    }
   ],
   "source": [
    "train_set, test_set, val_set = read_data(\"data5\", \"train_data\", \"test_data\", \"valid_data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_set_np = train_set.values\n",
    "test_set_np = test_set.values\n",
    "val_set_np = val_set.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def np_cleaner(train, test, val):\n",
    "    train = train[~np.isnan(train).any(axis=1)]\n",
    "    print \"Training set has %s rows and %s coumns\" %(train.shape[0], train.shape[1])\n",
    "    test = test[~np.isnan(test).any(axis=1)]\n",
    "    print \"Testing set has %s rows and %s coumns\" %(test.shape[0], test.shape[1])\n",
    "    val = val[~np.isnan(val).any(axis=1)]\n",
    "    print \"Validation set has %s rows and %s coumns\" %(val.shape[0], val.shape[1])\n",
    "    return train, test, val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set has 428 rows and 25 coumns\n",
      "Testing set has 142 rows and 25 coumns\n",
      "Validation set has 142 rows and 25 coumns\n"
     ]
    }
   ],
   "source": [
    "train_set_nb, test_set_nb, val_set_nb = np_cleaner(train_set_np, test_set_np, val_set_np)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set has 428 rows and 25 coumns\n",
      "Testing set has 142 rows and 25 coumns\n",
      "Validation set has 142 rows and 25 coumns\n"
     ]
    }
   ],
   "source": [
    "train_all, test_all, val_all = np_cleaner(train_set_np, test_set_np, val_set_np)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([u'GP', u'GS', u'MIN', u'FGM', u'FGA', u'FG%', u'3PM', u'3PA', u'3P%',\n",
       "       u'FTM', u'FTA', u'FT%', u'OFF', u'DEF', u'TRB', u'AST', u'STL', u'BLK',\n",
       "       u'PF', u'TOV', u'PTS', u'YR', u'POS', u'W', u'H'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_set.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "columns = {\"GP\":0, \"GS\":1, \"MIN\":2, \"FGM\":3,\"FGA\":4,\"FG%\":5,\"3PM\":6,\"3PA\":7,\"3P%\":8,\"FTM\":9,\"FTA\":10,\"FT%\":11,\"OFF\":12,\"DEF\":13,\n",
    "              \"TRB\":14,\"AST\":15,\"STL\":16,\"BLK\":17,\"PF\":18,\"TOV\":19,\"PTS\":20,\"YR\":21,\"POS\":22,\"W\":23,\"H\":24} "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def np_labeliser(train, test, val, col):\n",
    "    train = train[:,col]\n",
    "    test = test[:,col]\n",
    "    val = val[:,col]\n",
    "    return train, test, val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    " train_labels, test_labels, val_labels = np_labeliser(train_set_nb, test_set_nb, val_set_nb, 22)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def np_featuriser(train, test, val,feature_list):\n",
    "    \n",
    "    train = np.delete(train,feature_list,1)\n",
    "    test = np.delete(test,feature_list,1)\n",
    "    val = np.delete(val,feature_list,1)\n",
    "    \n",
    "    return train, test, val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "feature_list = [22]\n",
    "train_features_nb, test_features_nb, val_features_nb = np_featuriser(train_set_nb, test_set_nb, val_set_nb, feature_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Variance Threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def vt_fsel(train):\n",
    "    sel = VarianceThreshold(threshold=(.8 * (1 - .8)))\n",
    "    sel.fit_transform(train)\n",
    "    vt_list = sel.get_support()\n",
    "    l_vt = []\n",
    "    j = 0\n",
    "    for i in vt_list:\n",
    "        if i == False:\n",
    "            l_vt.append(j)\n",
    "            print \"%s. featue name: %s\" %(j, columns.keys()[columns.values().index(j)])\n",
    "        j = j+1\n",
    "    return l_vt    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5. featue name: FG%\n",
      "8. featue name: 3P%\n",
      "11. featue name: FT%\n"
     ]
    }
   ],
   "source": [
    "list_vt = vt_fsel(train_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.01470311  0.0074998   0.04611609  0.04593729  0.08357463  0.02805854\n",
      "  0.30318339  0.34438477  0.31151492  0.02153433  0.00746457  0.12981515\n",
      "  0.16454504  0.05304241  0.08644591  0.33475251  0.16157611  0.15386772\n",
      "  0.03772989  0.05008168  0.05688609  0.00259443  0.75265577  1.        ]\n",
      "Most valuable features: \n",
      "6 0.30318339431 3PM\n",
      "7 0.344384768543 3PA\n",
      "8 0.311514923218 3P%\n",
      "15 0.334752506224 AST\n",
      "23 0.752655766218 W\n",
      "24 1.0 H\n",
      "[0, 1, 2, 3, 4, 5, 9, 10, 11, 12, 13, 14, 16, 17, 18, 19, 20, 21, 22]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_selection import SelectPercentile, f_classif\n",
    "selector = SelectPercentile(f_classif, percentile=10)\n",
    "X = train_features_nb\n",
    "y = train_labels\n",
    "#print X[:1]\n",
    "selector.fit(X, y)\n",
    "scores = -np.log10(selector.pvalues_)\n",
    "#print scores\n",
    "scores /= scores.max()\n",
    "print scores\n",
    "\n",
    "#for i in scores:\n",
    "#scores\n",
    "\n",
    "print \"Most valuable features: \"\n",
    "remove = []\n",
    "for i in range(0,25):\n",
    "    remove.append(i)\n",
    "    \n",
    "j = 0\n",
    "for i in scores:\n",
    "    \n",
    "    if i>0.20:\n",
    "        print j, i, columns.keys()[columns.values().index(j)]\n",
    "        remove.remove(j)\n",
    "    if j == 21:\n",
    "        j = j+2\n",
    "    else:\n",
    "        j = j+1\n",
    "#for i in range(0,25)\n",
    "print remove"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "feature_list = [0, 1, 2, 3, 4, 6, 10, 11, 14, 19, 20, 21]\n",
    "train_features_nb, test_features_nb, val_features_nb = np_featuriser(train_set_nb, test_set_nb, val_set_nb, feature_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# All Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "list_none = [22]\n",
    "list_domain = [columns[\"GP\"],columns[\"GS\"],columns[\"MIN\"],columns[\"FG%\"],\n",
    "      columns[\"3P%\"],columns[\"FT%\"],columns[\"PTS\"],columns[\"YR\"],columns[\"POS\"],columns['3PM'],columns['FTM'],columns['FGM']]\n",
    "list_uni = [0, 1, 2, 3, 4, 5, 9, 10, 11, 12, 13, 14, 16, 17, 18, 19, 20, 21, 22]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#feature_list = [columns[\"GP\"],columns[\"GS\"],columns[\"MIN\"],columns[\"PTS\"],columns[\"FG%\"],\n",
    "#     columns[\"3P%\"],columns[\"FT%\"],columns[\"YR\"],columns[\"POS\"],columns['3PM'],columns['FTM'],columns['FGM']]\n",
    "#train_features_nb, test_features_nb, val_features_nb = np_featuriser(train_set_nb, test_set_nb, val_set_nb, feature_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def print_metrics(name, accuracy, conf_matrix):\n",
    "    print \"Feature selection: %s\\n\" %name\n",
    "    print \"Accuracy score: %s\\n\" %accuracy\n",
    "    print \"Confusion matrix:\"\n",
    "    print \"\\n%s\" %conf_matrix\n",
    "    print\"\\n\"\n",
    "    \n",
    "def clf(clf, tr, tr_labels, val, val_labels):\n",
    "        clf.fit(tr, tr_labels)\n",
    "        \n",
    "        pred = clf.predict(val)\n",
    "        \n",
    "        acc = metrics.accuracy_score(val_labels,pred)\n",
    "        conf = metrics.confusion_matrix(val_labels, pred)\n",
    "        \n",
    "        return acc, conf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def clf_all(CLF, l_none, l_domain, l_uni, train_all, test_all, val_all):\n",
    "    tr_none, ts_none, val_none = np_featuriser(train_all, test_all, val_all, l_none)\n",
    "    print tr_none.shape\n",
    "    tr_domain, ts_domain, val_domain = np_featuriser(train_all, test_all, val_all, l_domain)\n",
    "    \n",
    "    tr_uni, ts_uni, val_uni = np_featuriser(train_all, test_all, val_all, l_uni)\n",
    "   \n",
    "    \n",
    "    #clfnb = GaussianNB()\n",
    "    print \"Naive Bayes\\n\"\n",
    "    \n",
    "    acc_none, conf_none = clf(CLF, tr_none, train_labels, val_none, val_labels)\n",
    "    print_metrics(\"None\", acc_none, conf_none)\n",
    "    \n",
    "    acc_domain, conf_domain = clf(CLF, tr_domain, train_labels, val_domain, val_labels)\n",
    "    print_metrics(\"Domain knowledge\", acc_domain, conf_domain)\n",
    "\n",
    "    acc_uni, conf_uni = clf(CLF, tr_uni, train_labels, val_uni, val_labels)\n",
    "    print_metrics(\"Univariate\", acc_uni, conf_uni)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def clf_all(CLF, l_none, l_domain, l_uni, l_vt, train_all, test_all, val_all):\n",
    "    tr_none, ts_none, val_none = np_featuriser(train_all, test_all, val_all, l_none)\n",
    "    print tr_none.shape\n",
    "    tr_domain, ts_domain, val_domain = np_featuriser(train_all, test_all, val_all, l_domain)\n",
    "    \n",
    "    tr_uni, ts_uni, val_uni = np_featuriser(train_all, test_all, val_all, l_uni)\n",
    "    \n",
    "    tr_vt, ts_vt, val_vt = np_featuriser(train_all, test_all, val_all, l_vt)\n",
    "    \n",
    "    #clfnb = GaussianNB()\n",
    "    #print \"Naive Bayes\\n\"\n",
    "    \n",
    "    acc_none, conf_none = clf(CLF, tr_none, train_labels, ts_none, test_labels)\n",
    "    print_metrics(\"None\", acc_none, conf_none)\n",
    "    \n",
    "    acc_domain, conf_domain = clf(CLF, tr_domain, train_labels, ts_domain, test_labels)\n",
    "    print_metrics(\"Domain knowledge\", acc_domain, conf_domain)\n",
    "\n",
    "    acc_uni, conf_uni = clf(CLF, tr_uni, train_labels, ts_uni, test_labels)\n",
    "    print_metrics(\"Univariate\", acc_uni, conf_uni)\n",
    "    \n",
    "    acc_vt, conf_vt = clf(CLF, tr_vt, train_labels, ts_vt, test_labels)\n",
    "    print_metrics(\"Variance Threshold\", acc_vt, conf_vt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(428L, 24L)\n",
      "Feature selection: None\n",
      "\n",
      "Accuracy score: 0.661971830986\n",
      "\n",
      "Confusion matrix:\n",
      "\n",
      "[[13  0  0  0  0]\n",
      " [11 15  3  0  2]\n",
      " [ 0  3 14  0  1]\n",
      " [ 0  0  1 16 19]\n",
      " [ 0  0  0  8 36]]\n",
      "\n",
      "\n",
      "Feature selection: Domain knowledge\n",
      "\n",
      "Accuracy score: 0.725352112676\n",
      "\n",
      "Confusion matrix:\n",
      "\n",
      "[[13  0  0  0  0]\n",
      " [10 19  2  0  0]\n",
      " [ 0  2 16  0  0]\n",
      " [ 0  0  2 15 19]\n",
      " [ 0  0  0  4 40]]\n",
      "\n",
      "\n",
      "Feature selection: Univariate\n",
      "\n",
      "Accuracy score: 0.683098591549\n",
      "\n",
      "Confusion matrix:\n",
      "\n",
      "[[13  0  0  0  0]\n",
      " [ 6 21  3  0  1]\n",
      " [ 0  3 13  1  1]\n",
      " [ 0  0  3  7 26]\n",
      " [ 0  0  0  1 43]]\n",
      "\n",
      "\n",
      "Feature selection: Variance Threshold\n",
      "\n",
      "Accuracy score: 1.0\n",
      "\n",
      "Confusion matrix:\n",
      "\n",
      "[[13  0  0  0  0]\n",
      " [ 0 31  0  0  0]\n",
      " [ 0  0 18  0  0]\n",
      " [ 0  0  0 36  0]\n",
      " [ 0  0  0  0 44]]\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clfnb = GaussianNB()\n",
    "clf_all(clfnb, list_none, list_domain, list_uni, list_vt, train_all, test_all, val_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(428L, 24L)\n",
      "Feature selection: None\n",
      "\n",
      "Accuracy score: 0.802816901408\n",
      "\n",
      "Confusion matrix:\n",
      "\n",
      "[[10  3  0  0  0]\n",
      " [ 4 24  3  0  0]\n",
      " [ 1  4 13  0  0]\n",
      " [ 0  0  2 29  5]\n",
      " [ 0  0  0  6 38]]\n",
      "\n",
      "\n",
      "Feature selection: Domain knowledge\n",
      "\n",
      "Accuracy score: 0.830985915493\n",
      "\n",
      "Confusion matrix:\n",
      "\n",
      "[[13  0  0  0  0]\n",
      " [ 4 24  3  0  0]\n",
      " [ 1  4 13  0  0]\n",
      " [ 0  0  1 29  6]\n",
      " [ 0  0  0  5 39]]\n",
      "\n",
      "\n",
      "Feature selection: Univariate\n",
      "\n",
      "Accuracy score: 0.830985915493\n",
      "\n",
      "Confusion matrix:\n",
      "\n",
      "[[13  0  0  0  0]\n",
      " [ 6 22  3  0  0]\n",
      " [ 1  2 15  0  0]\n",
      " [ 0  0  2 26  8]\n",
      " [ 0  0  0  2 42]]\n",
      "\n",
      "\n",
      "Feature selection: Variance Threshold\n",
      "\n",
      "Accuracy score: 0.992957746479\n",
      "\n",
      "Confusion matrix:\n",
      "\n",
      "[[13  0  0  0  0]\n",
      " [ 0 31  0  0  0]\n",
      " [ 0  0 18  0  0]\n",
      " [ 0  0  0 36  0]\n",
      " [ 0  0  1  0 43]]\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "svm = SVC()\n",
    "svm.set_params(kernel='linear')\n",
    "clf_all(svm, list_none, list_domain, list_uni, list_vt, train_all, test_all, val_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(428L, 24L)\n",
      "Feature selection: None\n",
      "\n",
      "Accuracy score: 0.69014084507\n",
      "\n",
      "Confusion matrix:\n",
      "\n",
      "[[11  2  0  0  0]\n",
      " [ 6 17  7  1  0]\n",
      " [ 1  6  8  3  0]\n",
      " [ 0  0  2 20 14]\n",
      " [ 0  0  0  2 42]]\n",
      "\n",
      "\n",
      "Feature selection: Domain knowledge\n",
      "\n",
      "Accuracy score: 0.725352112676\n",
      "\n",
      "Confusion matrix:\n",
      "\n",
      "[[13  0  0  0  0]\n",
      " [ 7 19  5  0  0]\n",
      " [ 1  4  8  5  0]\n",
      " [ 0  0  3 21 12]\n",
      " [ 0  0  0  2 42]]\n",
      "\n",
      "\n",
      "Feature selection: Univariate\n",
      "\n",
      "Accuracy score: 0.640845070423\n",
      "\n",
      "Confusion matrix:\n",
      "\n",
      "[[13  0  0  0  0]\n",
      " [ 9 14  7  1  0]\n",
      " [ 1  5  6  6  0]\n",
      " [ 0  1  1 15 19]\n",
      " [ 0  0  0  1 43]]\n",
      "\n",
      "\n",
      "Feature selection: Variance Threshold\n",
      "\n",
      "Accuracy score: 0.880281690141\n",
      "\n",
      "Confusion matrix:\n",
      "\n",
      "[[13  0  0  0  0]\n",
      " [ 2 23  4  2  0]\n",
      " [ 0  2 14  2  0]\n",
      " [ 0  0  4 31  1]\n",
      " [ 0  0  0  0 44]]\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "logreg = linear_model.LogisticRegression(C=1e5)\n",
    "clf_all(logreg, list_none, list_domain, list_uni, list_vt, train_all, test_all, val_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
