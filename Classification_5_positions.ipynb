{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from pandas import DataFrame\n",
    "import pandas as pd\n",
    "import scipy as sp\n",
    "from sklearn import metrics\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn import linear_model\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.feature_selection import VarianceThreshold"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reading data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def read_data(folder, name1, name2, name3):\n",
    "    loc = \"%s/%s.txt\" %(folder, name1)\n",
    "    train_set = pd.read_csv(loc, sep=\"\\t\")\n",
    "    print \"Training set has %s rows and %s coumns\" %(train_set.shape[0], train_set.shape[1])\n",
    "    loc = \"%s/%s.txt\" %(folder, name2)\n",
    "    test_set = pd.read_csv(loc, sep=\"\\t\")\n",
    "    print \"Testing set has %s rows and %s coumns\" %(test_set.shape[0], test_set.shape[1])\n",
    "    loc = \"%s/%s.txt\" %(folder, name3)\n",
    "    val_set = pd.read_csv(loc, sep=\"\\t\")\n",
    "    print \"Validation set has %s rows and %s coumns\" %(val_set.shape[0], val_set.shape[1])\n",
    "    return train_set, test_set, val_set\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set has 428 rows and 25 coumns\n",
      "Testing set has 142 rows and 25 coumns\n",
      "Validation set has 142 rows and 25 coumns\n"
     ]
    }
   ],
   "source": [
    "train_set, test_set, val_set = read_data(\"data5\", \"train_data\", \"test_data\", \"valid_data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_set_np = train_set.values\n",
    "test_set_np = test_set.values\n",
    "val_set_np = val_set.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def np_cleaner(train, test, val):\n",
    "    train = train[~np.isnan(train).any(axis=1)]\n",
    "    print \"Training set has %s rows and %s coumns\" %(train.shape[0], train.shape[1])\n",
    "    test = test[~np.isnan(test).any(axis=1)]\n",
    "    print \"Testing set has %s rows and %s coumns\" %(test.shape[0], test.shape[1])\n",
    "    val = val[~np.isnan(val).any(axis=1)]\n",
    "    print \"Validation set has %s rows and %s coumns\" %(val.shape[0], val.shape[1])\n",
    "    return train, test, val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set has 428 rows and 25 coumns\n",
      "Testing set has 142 rows and 25 coumns\n",
      "Validation set has 142 rows and 25 coumns\n"
     ]
    }
   ],
   "source": [
    "train_set_nb, test_set_nb, val_set_nb = np_cleaner(train_set_np, test_set_np, val_set_np)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set has 428 rows and 25 coumns\n",
      "Testing set has 142 rows and 25 coumns\n",
      "Validation set has 142 rows and 25 coumns\n"
     ]
    }
   ],
   "source": [
    "train_all, test_all, val_all = np_cleaner(train_set_np, test_set_np, val_set_np)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([u'GP', u'GS', u'MIN', u'FGM', u'FGA', u'FG%', u'3PM', u'3PA', u'3P%',\n",
       "       u'FTM', u'FTA', u'FT%', u'OFF', u'DEF', u'TRB', u'AST', u'STL', u'BLK',\n",
       "       u'PF', u'TOV', u'PTS', u'YR', u'POS', u'W', u'H'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_set.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "columns = {\"GP\":0, \"GS\":1, \"MIN\":2, \"FGM\":3,\"FGA\":4,\"FG%\":5,\"3PM\":6,\"3PA\":7,\"3P%\":8,\"FTM\":9,\"FTA\":10,\"FT%\":11,\"OFF\":12,\"DEF\":13,\n",
    "              \"TRB\":14,\"AST\":15,\"STL\":16,\"BLK\":17,\"PF\":18,\"TOV\":19,\"PTS\":20,\"YR\":21,\"POS\":22,\"W\":23,\"H\":24} "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def np_labeliser(train, test, val, col):\n",
    "    train = train[:,col]\n",
    "    test = test[:,col]\n",
    "    val = val[:,col]\n",
    "    return train, test, val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    " train_labels, test_labels, val_labels = np_labeliser(train_set_nb, test_set_nb, val_set_nb, 22)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def np_featuriser(train, test, val,feature_list):\n",
    "    \n",
    "    train = np.delete(train,feature_list,1)\n",
    "    test = np.delete(test,feature_list,1)\n",
    "    val = np.delete(val,feature_list,1)\n",
    "    \n",
    "    return train, test, val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "feature_list = [22]\n",
    "train_features_nb, test_features_nb, val_features_nb = np_featuriser(train_set_nb, test_set_nb, val_set_nb, feature_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Variance Threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def vt_fsel(train):\n",
    "    sel = VarianceThreshold(threshold=(.8 * (1 - .8)))\n",
    "    sel.fit_transform(train)\n",
    "    vt_list = sel.get_support()\n",
    "    l_vt = []\n",
    "    j = 0\n",
    "    for i in vt_list:\n",
    "        if i == False:\n",
    "            l_vt.append(j)\n",
    "            print \"%s. featue name: %s\" %(j, columns.keys()[columns.values().index(j)])\n",
    "        j = j+1\n",
    "    return l_vt    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5. featue name: FG%\n",
      "8. featue name: 3P%\n",
      "11. featue name: FT%\n"
     ]
    }
   ],
   "source": [
    "list_vt = vt_fsel(train_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.01470311  0.0074998   0.04611609  0.04593729  0.08357463  0.02805854\n",
      "  0.30318339  0.34438477  0.31151492  0.02153433  0.00746457  0.12981515\n",
      "  0.16454504  0.05304241  0.08644591  0.33475251  0.16157611  0.15386772\n",
      "  0.03772989  0.05008168  0.05688609  0.00259443  0.75265577  1.        ]\n",
      "Most valuable features: \n",
      "6 0.30318339431 3PM\n",
      "7 0.344384768543 3PA\n",
      "8 0.311514923218 3P%\n",
      "15 0.334752506224 AST\n",
      "23 0.752655766218 W\n",
      "24 1.0 H\n",
      "[0, 1, 2, 3, 4, 5, 9, 10, 11, 12, 13, 14, 16, 17, 18, 19, 20, 21, 22]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_selection import SelectPercentile, f_classif\n",
    "selector = SelectPercentile(f_classif, percentile=10)\n",
    "X = train_features_nb\n",
    "y = train_labels\n",
    "#print X[:1]\n",
    "selector.fit(X, y)\n",
    "scores = -np.log10(selector.pvalues_)\n",
    "#print scores\n",
    "scores /= scores.max()\n",
    "print scores\n",
    "\n",
    "#for i in scores:\n",
    "#scores\n",
    "\n",
    "print \"Most valuable features: \"\n",
    "remove = []\n",
    "for i in range(0,25):\n",
    "    remove.append(i)\n",
    "    \n",
    "j = 0\n",
    "for i in scores:\n",
    "    \n",
    "    if i>0.20:\n",
    "        print j, i, columns.keys()[columns.values().index(j)]\n",
    "        remove.remove(j)\n",
    "    if j == 21:\n",
    "        j = j+2\n",
    "    else:\n",
    "        j = j+1\n",
    "#for i in range(0,25)\n",
    "print remove"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "feature_list = [0, 1, 2, 3, 4, 6, 10, 11, 14, 19, 20, 21]\n",
    "train_features_nb, test_features_nb, val_features_nb = np_featuriser(train_set_nb, test_set_nb, val_set_nb, feature_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#feature_list = [columns[\"GP\"],columns[\"GS\"],columns[\"MIN\"],columns[\"PTS\"],columns[\"FG%\"],\n",
    "#     columns[\"3P%\"],columns[\"FT%\"],columns[\"YR\"],columns[\"POS\"],columns['3PM'],columns['FTM'],columns['FGM']]\n",
    "#train_features_nb, test_features_nb, val_features_nb = np_featuriser(train_set_nb, test_set_nb, val_set_nb, feature_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clfNB = GaussianNB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GaussianNB()"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clfNB.fit(train_features_nb, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "predNB = clfNB.predict(val_features_nb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Accuracy Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accNB = metrics.accuracy_score(val_labels,predNB)\n",
    "accNB\n",
    "# first try, with all features - 66%\n",
    "# second, GP, GS, PTS, FG%, 3P%, FT%, YR, POS, 3PM, FTM, FGM removed - 73%\n",
    "# third - Univariate feature selection \"Select K best\" - 47% only two features GP i GS\n",
    "# fourth - Univariate feature selection \"SelectPercentile, f_classif\" 74,6%\n",
    "######THIS WAS WITH TRAIN FEATURES!!!!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Confusion Matrix Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[20,  0,  0,  0,  0],\n",
       "       [ 0, 26,  0,  0,  0],\n",
       "       [ 0,  0, 22,  0,  0],\n",
       "       [ 0,  0,  0, 35,  0],\n",
       "       [ 0,  0,  0,  0, 39]])"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confm_nb = metrics.confusion_matrix(val_labels, predNB)\n",
    "confm_nb\n",
    "# labels 1 - 2 - 3 - 4 - 5 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "clfSVM= SVC()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0, degree=3, gamma=0.0,\n",
       "  kernel='linear', max_iter=-1, probability=False, random_state=None,\n",
       "  shrinking=True, tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clfSVM.set_params(kernel = 'linear')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0, degree=3, gamma=0.0,\n",
       "  kernel='linear', max_iter=-1, probability=False, random_state=None,\n",
       "  shrinking=True, tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clfSVM.fit(train_features_nb, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "predSVM = clfSVM.predict(val_features_nb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Accuracy SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accSVM = metrics.accuracy_score(val_labels,predSVM)\n",
    "accSVM\n",
    "# first try - 78% same features as nb\n",
    "# second try - 82,4% kernel='linear'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Confusion Matrix SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[20,  0,  0,  0,  0],\n",
       "       [ 0, 26,  0,  0,  0],\n",
       "       [ 0,  0, 22,  0,  0],\n",
       "       [ 0,  0,  0, 35,  0],\n",
       "       [ 0,  0,  0,  0, 39]])"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confm_svm = metrics.confusion_matrix(val_labels, predSVM)\n",
    "confm_svm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lr_feature_list = [22]\n",
    "train_features_lr, test_features_lr, val_features_lr = np_featuriser(train_set_nb, test_set_nb, val_set_nb,lr_feature_list)\n",
    "\n",
    "lr_feature_list = [0, 1, 2, 3, 18, 19, 20, 21, 22]\n",
    "train_features_lr, test_features_lr, val_features_lr = np_featuriser(train_set_nb, test_set_nb, val_set_nb,lr_feature_list)\n",
    "\n",
    "\n",
    "#columns = {\"GP\":0, \"GS\":1, \"MIN\":2, \"FGM\":3,\"FGA\":4,\"FG%\":5,\"3PM\":6,\"3PA\":7,\"3P%\":8,\"FTM\":9,\"FTA\":10,\"FT%\":11,\"OFF\":12,\"DEF\":13,\n",
    "#              \"TRB\":14,\"AST\":15,\"STL\":16,\"BLK\":17,\"PF\":18,\"TOV\":19,\"PTS\":20,\"YR\":21,\"POS\":22,\"W\":23,\"H\":24} "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#for i in remove:\n",
    "#    print i\n",
    "#    print columns.keys()[columns.values().index(i)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "logreg = linear_model.LogisticRegression(C=1e5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=100000.0, class_weight=None, dual=False,\n",
       "          fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
       "          multi_class='ovr', penalty='l2', random_state=None,\n",
       "          solver='liblinear', tol=0.0001, verbose=0)"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logreg.fit(train_features_lr, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "predLR = logreg.predict(val_features_lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Accuracy Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.66901408450704225"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accLR = metrics.accuracy_score(predLR, val_labels)\n",
    "accLR\n",
    "# first try 74,6%\n",
    "# 88,7% sa fsel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Confusion Matrix Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[16,  3,  0,  1,  0],\n",
       "       [ 5, 14,  6,  1,  0],\n",
       "       [ 0,  4, 14,  4,  0],\n",
       "       [ 1,  1,  4, 18, 11],\n",
       "       [ 1,  0,  2,  3, 33]])"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confm_lr = metrics.confusion_matrix(val_labels, predLR)\n",
    "confm_lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "list_none = [22]\n",
    "list_domain = [columns[\"GP\"],columns[\"GS\"],columns[\"MIN\"],columns[\"FG%\"],\n",
    "      columns[\"3P%\"],columns[\"FT%\"],columns[\"PTS\"],columns[\"YR\"],columns[\"POS\"],columns['3PM'],columns['FTM'],columns['FGM']]\n",
    "list_uni = [0, 1, 2, 3, 4, 5, 9, 10, 11, 12, 13, 14, 16, 17, 18, 19, 20, 21, 22]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def print_metrics(name, accuracy, conf_matrix):\n",
    "    print \"Feature selection: %s\\n\" %name\n",
    "    print \"Accuracy score: %s\\n\" %accuracy\n",
    "    print \"Confusion matrix:\"\n",
    "    print \"\\n%s\" %conf_matrix\n",
    "    print\"\\n\"\n",
    "    \n",
    "def clf(clf, tr, tr_labels, val, val_labels):\n",
    "        clf.fit(tr, tr_labels)\n",
    "        \n",
    "        pred = clf.predict(val)\n",
    "        \n",
    "        acc = metrics.accuracy_score(val_labels,pred)\n",
    "        conf = metrics.confusion_matrix(val_labels, pred)\n",
    "        \n",
    "        return acc, conf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def clf_all(CLF, l_none, l_domain, l_uni, train_all, test_all, val_all):\n",
    "    tr_none, ts_none, val_none = np_featuriser(train_all, test_all, val_all, l_none)\n",
    "    print tr_none.shape\n",
    "    tr_domain, ts_domain, val_domain = np_featuriser(train_all, test_all, val_all, l_domain)\n",
    "    \n",
    "    tr_uni, ts_uni, val_uni = np_featuriser(train_all, test_all, val_all, l_uni)\n",
    "   \n",
    "    \n",
    "    #clfnb = GaussianNB()\n",
    "    print \"Naive Bayes\\n\"\n",
    "    \n",
    "    acc_none, conf_none = clf(CLF, tr_none, train_labels, val_none, val_labels)\n",
    "    print_metrics(\"None\", acc_none, conf_none)\n",
    "    \n",
    "    acc_domain, conf_domain = clf(CLF, tr_domain, train_labels, val_domain, val_labels)\n",
    "    print_metrics(\"Domain knowledge\", acc_domain, conf_domain)\n",
    "\n",
    "    acc_uni, conf_uni = clf(CLF, tr_uni, train_labels, val_uni, val_labels)\n",
    "    print_metrics(\"Univariate\", acc_uni, conf_uni)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def clf_all(CLF, l_none, l_domain, l_uni, l_vt, train_all, test_all, val_all):\n",
    "    tr_none, ts_none, val_none = np_featuriser(train_all, test_all, val_all, l_none)\n",
    "    print tr_none.shape\n",
    "    tr_domain, ts_domain, val_domain = np_featuriser(train_all, test_all, val_all, l_domain)\n",
    "    \n",
    "    tr_uni, ts_uni, val_uni = np_featuriser(train_all, test_all, val_all, l_uni)\n",
    "    \n",
    "    tr_vt, ts_vt, val_vt = np_featuriser(train_all, test_all, val_all, l_vt)\n",
    "    \n",
    "    #clfnb = GaussianNB()\n",
    "    #print \"Naive Bayes\\n\"\n",
    "    \n",
    "    acc_none, conf_none = clf(CLF, tr_none, train_labels, ts_none, test_labels)\n",
    "    print_metrics(\"None\", acc_none, conf_none)\n",
    "    \n",
    "    acc_domain, conf_domain = clf(CLF, tr_domain, train_labels, ts_domain, test_labels)\n",
    "    print_metrics(\"Domain knowledge\", acc_domain, conf_domain)\n",
    "\n",
    "    acc_uni, conf_uni = clf(CLF, tr_uni, train_labels, ts_uni, test_labels)\n",
    "    print_metrics(\"Univariate\", acc_uni, conf_uni)\n",
    "    \n",
    "    acc_vt, conf_vt = clf(CLF, tr_vt, train_labels, ts_vt, test_labels)\n",
    "    print_metrics(\"Variance Threshold\", acc_vt, conf_vt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(428L, 24L)\n",
      "Feature selection: None\n",
      "\n",
      "Accuracy score: 0.661971830986\n",
      "\n",
      "Confusion matrix:\n",
      "\n",
      "[[13  0  0  0  0]\n",
      " [11 15  3  0  2]\n",
      " [ 0  3 14  0  1]\n",
      " [ 0  0  1 16 19]\n",
      " [ 0  0  0  8 36]]\n",
      "\n",
      "\n",
      "Feature selection: Domain knowledge\n",
      "\n",
      "Accuracy score: 0.725352112676\n",
      "\n",
      "Confusion matrix:\n",
      "\n",
      "[[13  0  0  0  0]\n",
      " [10 19  2  0  0]\n",
      " [ 0  2 16  0  0]\n",
      " [ 0  0  2 15 19]\n",
      " [ 0  0  0  4 40]]\n",
      "\n",
      "\n",
      "Feature selection: Univariate\n",
      "\n",
      "Accuracy score: 0.683098591549\n",
      "\n",
      "Confusion matrix:\n",
      "\n",
      "[[13  0  0  0  0]\n",
      " [ 6 21  3  0  1]\n",
      " [ 0  3 13  1  1]\n",
      " [ 0  0  3  7 26]\n",
      " [ 0  0  0  1 43]]\n",
      "\n",
      "\n",
      "Feature selection: Variance Threshold\n",
      "\n",
      "Accuracy score: 1.0\n",
      "\n",
      "Confusion matrix:\n",
      "\n",
      "[[13  0  0  0  0]\n",
      " [ 0 31  0  0  0]\n",
      " [ 0  0 18  0  0]\n",
      " [ 0  0  0 36  0]\n",
      " [ 0  0  0  0 44]]\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clfnb = GaussianNB()\n",
    "clf_all(clfnb, list_none, list_domain, list_uni, list_vt, train_all, test_all, val_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(428L, 24L)\n",
      "Feature selection: None\n",
      "\n",
      "Accuracy score: 0.711267605634\n",
      "\n",
      "Confusion matrix:\n",
      "\n",
      "[[18  2  0  0  0]\n",
      " [ 8 15  3  0  0]\n",
      " [ 0  3 15  4  0]\n",
      " [ 0  0  7 21  7]\n",
      " [ 0  0  0  7 32]]\n",
      "\n",
      "\n",
      "Feature selection: Domain knowledge\n",
      "\n",
      "Accuracy score: 0.753521126761\n",
      "\n",
      "Confusion matrix:\n",
      "\n",
      "[[18  2  0  0  0]\n",
      " [ 2 19  5  0  0]\n",
      " [ 0  4 13  5  0]\n",
      " [ 0  0  4 22  9]\n",
      " [ 0  0  0  4 35]]\n",
      "\n",
      "\n",
      "Feature selection: Univariate\n",
      "\n",
      "Accuracy score: 0.725352112676\n",
      "\n",
      "Confusion matrix:\n",
      "\n",
      "[[17  3  0  0  0]\n",
      " [ 2 16  8  0  0]\n",
      " [ 0  4 12  6  0]\n",
      " [ 0  0  3 23  9]\n",
      " [ 0  0  0  4 35]]\n",
      "\n",
      "\n",
      "Feature selection: Variance Threshold\n",
      "\n",
      "Accuracy score: 0.992957746479\n",
      "\n",
      "Confusion matrix:\n",
      "\n",
      "[[20  0  0  0  0]\n",
      " [ 0 26  0  0  0]\n",
      " [ 0  0 22  0  0]\n",
      " [ 0  0  1 34  0]\n",
      " [ 0  0  0  0 39]]\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "svm = SVC()\n",
    "svm.set_params(kernel='linear')\n",
    "clf_all(svm, list_none, list_domain, list_uni, list_vt, train_all, test_all, val_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(428L, 24L)\n",
      "Feature selection: None\n",
      "\n",
      "Accuracy score: 0.570422535211\n",
      "\n",
      "Confusion matrix:\n",
      "\n",
      "[[14  4  2  0  0]\n",
      " [ 6 12  6  2  0]\n",
      " [ 2  3 13  4  0]\n",
      " [ 0  1  5 11 18]\n",
      " [ 0  0  2  6 31]]\n",
      "\n",
      "\n",
      "Feature selection: Domain knowledge\n",
      "\n",
      "Accuracy score: 0.669014084507\n",
      "\n",
      "Confusion matrix:\n",
      "\n",
      "[[16  4  0  0  0]\n",
      " [ 7 14  2  3  0]\n",
      " [ 1  5 10  6  0]\n",
      " [ 0  2  1 19 13]\n",
      " [ 0  0  0  3 36]]\n",
      "\n",
      "\n",
      "Feature selection: Univariate\n",
      "\n",
      "Accuracy score: 0.598591549296\n",
      "\n",
      "Confusion matrix:\n",
      "\n",
      "[[15  2  1  2  0]\n",
      " [ 6  7  6  7  0]\n",
      " [ 0  4 12  6  0]\n",
      " [ 0  1  3 15 16]\n",
      " [ 0  0  3  0 36]]\n",
      "\n",
      "\n",
      "Feature selection: Variance Threshold\n",
      "\n",
      "Accuracy score: 0.802816901408\n",
      "\n",
      "Confusion matrix:\n",
      "\n",
      "[[18  2  0  0  0]\n",
      " [ 0 18  6  2  0]\n",
      " [ 0  2 13  7  0]\n",
      " [ 0  0  9 26  0]\n",
      " [ 0  0  0  0 39]]\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "logreg = linear_model.LogisticRegression(C=1e5)\n",
    "clf_all(logreg, list_none, list_domain, list_uni, list_vt, train_all, test_all, val_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
