{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from pandas import DataFrame\n",
    "import pandas as pd\n",
    "import scipy as sp\n",
    "from sklearn import metrics\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn import linear_model\n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reading data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def read_data(folder, name1, name2, name3):\n",
    "    loc = \"%s/%s.txt\" %(folder, name1)\n",
    "    train_set = pd.read_csv(loc, sep=\"\\t\")\n",
    "    print \"Training set has %s rows and %s coumns\" %(train_set.shape[0], train_set.shape[1])\n",
    "    loc = \"%s/%s.txt\" %(folder, name2)\n",
    "    test_set = pd.read_csv(loc, sep=\"\\t\")\n",
    "    print \"Testing set has %s rows and %s coumns\" %(test_set.shape[0], test_set.shape[1])\n",
    "    loc = \"%s/%s.txt\" %(folder, name3)\n",
    "    val_set = pd.read_csv(loc, sep=\"\\t\")\n",
    "    print \"Validation set has %s rows and %s coumns\" %(val_set.shape[0], val_set.shape[1])\n",
    "    return train_set, test_set, val_set\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set has 428 rows and 25 coumns\n",
      "Testing set has 142 rows and 25 coumns\n",
      "Validation set has 142 rows and 25 coumns\n"
     ]
    }
   ],
   "source": [
    "train_set, test_set, val_set = read_data(\"data5\", \"train_data\", \"test_data\", \"valid_data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_set_np = train_set.values\n",
    "test_set_np = test_set.values\n",
    "val_set_np = val_set.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def np_cleaner(train, test, val):\n",
    "    train = train[~np.isnan(train).any(axis=1)]\n",
    "    print \"Training set has %s rows and %s coumns\" %(train.shape[0], train.shape[1])\n",
    "    test = test[~np.isnan(test).any(axis=1)]\n",
    "    print \"Testing set has %s rows and %s coumns\" %(test.shape[0], test.shape[1])\n",
    "    val = val[~np.isnan(val).any(axis=1)]\n",
    "    print \"Validation set has %s rows and %s coumns\" %(val.shape[0], val.shape[1])\n",
    "    return train, test, val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set has 428 rows and 25 coumns\n",
      "Testing set has 142 rows and 25 coumns\n",
      "Validation set has 142 rows and 25 coumns\n"
     ]
    }
   ],
   "source": [
    "train_set_nb, test_set_nb, val_set_nb = np_cleaner(train_set_np, test_set_np, val_set_np)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([u'GP', u'GS', u'MIN', u'FGM', u'FGA', u'FG%', u'3PM', u'3PA', u'3P%',\n",
       "       u'FTM', u'FTA', u'FT%', u'OFF', u'DEF', u'TRB', u'AST', u'STL', u'BLK',\n",
       "       u'PF', u'TOV', u'PTS', u'YR', u'POS', u'W', u'H'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_set.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "columns = {\"GP\":0, \"GS\":1, \"MIN\":2, \"FGM\":3,\"FGA\":4,\"FG%\":5,\"3PM\":6,\"3PA\":7,\"3P%\":8,\"FTM\":9,\"FTA\":10,\"FT%\":11,\"OFF\":12,\"DEF\":13,\n",
    "              \"TRB\":14,\"AST\":15,\"STL\":16,\"BLK\":17,\"PF\":18,\"TOV\":19,\"PTS\":20,\"YR\":21,\"POS\":22,\"W\":23,\"H\":24} "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def np_labeliser(train, test, val, col):\n",
    "    train = train[:,col]\n",
    "    test = test[:,col]\n",
    "    val = val[:,col]\n",
    "    return train, test, val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    " train_labels, test_labels, val_labels = np_labeliser(train_set_nb, test_set_nb, val_set_nb, 22)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def np_featuriser(train, test, val,feature_lsit):\n",
    "    \n",
    "    train = np.delete(train,feature_list,1)\n",
    "    test = np.delete(test,feature_list,1)\n",
    "    val = np.delete(val,feature_list,1)\n",
    "    \n",
    "    return train, test, val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "feature_list = [22]\n",
    "train_features_nb, test_features_nb, val_features_nb = np_featuriser(train_set_nb, test_set_nb, val_set_nb, feature_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.01470311  0.0074998   0.04611609  0.04593729  0.08357463  0.02805854\n",
      "  0.30318339  0.34438477  0.31151492  0.02153433  0.00746457  0.12981515\n",
      "  0.16454504  0.05304241  0.08644591  0.33475251  0.16157611  0.15386772\n",
      "  0.03772989  0.05008168  0.05688609  0.00259443  0.75265577  1.        ]\n",
      "Most valuable features: \n",
      "4 0.0835746288741 FGA\n",
      "6 0.30318339431 3PM\n",
      "7 0.344384768543 3PA\n",
      "8 0.311514923218 3P%\n",
      "11 0.129815150674 FT%\n",
      "12 0.164545043096 OFF\n",
      "14 0.0864459081968 TRB\n",
      "15 0.334752506224 AST\n",
      "16 0.16157611031 STL\n",
      "17 0.15386772173 BLK\n",
      "23 0.752655766218 W\n",
      "24 1.0 H\n",
      "[0, 1, 2, 3, 5, 9, 10, 13, 18, 19, 20, 21, 22]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_selection import SelectPercentile, f_classif\n",
    "selector = SelectPercentile(f_classif, percentile=10)\n",
    "X = train_features_nb\n",
    "y = train_labels\n",
    "#print X[:1]\n",
    "selector.fit(X, y)\n",
    "scores = -np.log10(selector.pvalues_)\n",
    "#print scores\n",
    "scores /= scores.max()\n",
    "print scores\n",
    "\n",
    "#for i in scores:\n",
    "#scores\n",
    "\n",
    "print \"Most valuable features: \"\n",
    "remove = []\n",
    "for i in range(0,25):\n",
    "    remove.append(i)\n",
    "    \n",
    "j = 0\n",
    "for i in scores:\n",
    "    \n",
    "    if i>0.08:\n",
    "        print j, i, columns.keys()[columns.values().index(j)]\n",
    "        remove.remove(j)\n",
    "    if j == 21:\n",
    "        j = j+2\n",
    "    else:\n",
    "        j = j+1\n",
    "#for i in range(0,25)\n",
    "print remove"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "feature_list = [0, 1, 2, 3, 4, 6, 10, 11, 14, 19, 20, 21]\n",
    "train_features_nb, test_features_nb, val_features_nb = np_featuriser(train_set_nb, test_set_nb, val_set_nb, feature_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#feature_list = [columns[\"GP\"],columns[\"GS\"],columns[\"MIN\"],columns[\"PTS\"],columns[\"FG%\"],\n",
    "#     columns[\"3P%\"],columns[\"FT%\"],columns[\"YR\"],columns[\"POS\"],columns['3PM'],columns['FTM'],columns['FGM']]\n",
    "#train_features_nb, test_features_nb, val_features_nb = np_featuriser(train_set_nb, test_set_nb, val_set_nb, feature_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clfNB = GaussianNB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GaussianNB()"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clfNB.fit(train_features_nb, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "predNB = clfNB.predict(val_features_nb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Accuracy Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accNB = metrics.accuracy_score(val_labels,predNB)\n",
    "accNB\n",
    "# first try, with all features - 66%\n",
    "# second, GP, GS, PTS, FG%, 3P%, FT%, YR, POS, 3PM, FTM, FGM removed - 73%\n",
    "# third - Univariate feature selection \"Select K best\" - 47% only two features GP i GS\n",
    "# fourth - Univariate feature selection \"SelectPercentile, f_classif\" 74,6%\n",
    "######THIS WAS WITH TRAIN FEATURES!!!!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Confusion Matrix Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[20,  0,  0,  0,  0],\n",
       "       [ 0, 26,  0,  0,  0],\n",
       "       [ 0,  0, 22,  0,  0],\n",
       "       [ 0,  0,  0, 35,  0],\n",
       "       [ 0,  0,  0,  0, 39]])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confm_nb = metrics.confusion_matrix(val_labels, predNB)\n",
    "confm_nb\n",
    "# labels 1 - 2 - 3 - 4 - 5 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "clfSVM= SVC()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0, degree=3, gamma=0.0,\n",
       "  kernel='linear', max_iter=-1, probability=False, random_state=None,\n",
       "  shrinking=True, tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clfSVM.set_params(kernel = 'linear')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0, degree=3, gamma=0.0,\n",
       "  kernel='linear', max_iter=-1, probability=False, random_state=None,\n",
       "  shrinking=True, tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clfSVM.fit(train_features_nb, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "predSVM = clfSVM.predict(val_features_nb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Accuracy SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accSVM = metrics.accuracy_score(val_labels,predSVM)\n",
    "accSVM\n",
    "# first try - 78% same features as nb\n",
    "# second try - 82,4% kernel='linear'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Confusion Matrix SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[20,  0,  0,  0,  0],\n",
       "       [ 0, 26,  0,  0,  0],\n",
       "       [ 0,  0, 22,  0,  0],\n",
       "       [ 0,  0,  0, 35,  0],\n",
       "       [ 0,  0,  0,  0, 39]])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confm_svm = metrics.confusion_matrix(val_labels, predSVM)\n",
    "confm_svm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lr_feature_list = [22]\n",
    "train_features_lr, test_features_lr, val_features_lr = np_featuriser(train_set_nb, test_set_nb, val_set_nb,lr_feature_list)\n",
    "\n",
    "lr_feature_list = [0, 1, 2, 3, 18, 19, 20, 21, 22]\n",
    "train_features_lr, test_features_lr, val_features_lr = np_featuriser(train_set_nb, test_set_nb, val_set_nb,lr_feature_list)\n",
    "\n",
    "\n",
    "#columns = {\"GP\":0, \"GS\":1, \"MIN\":2, \"FGM\":3,\"FGA\":4,\"FG%\":5,\"3PM\":6,\"3PA\":7,\"3P%\":8,\"FTM\":9,\"FTA\":10,\"FT%\":11,\"OFF\":12,\"DEF\":13,\n",
    "#              \"TRB\":14,\"AST\":15,\"STL\":16,\"BLK\":17,\"PF\":18,\"TOV\":19,\"PTS\":20,\"YR\":21,\"POS\":22,\"W\":23,\"H\":24} "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#for i in remove:\n",
    "#    print i\n",
    "#    print columns.keys()[columns.values().index(i)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "logreg = linear_model.LogisticRegression(C=1e5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=100000.0, class_weight=None, dual=False,\n",
       "          fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
       "          multi_class='ovr', penalty='l2', random_state=None,\n",
       "          solver='liblinear', tol=0.0001, verbose=0)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logreg.fit(train_features_lr, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "predLR = logreg.predict(val_features_lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Accuracy Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.87323943661971826"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accLR = metrics.accuracy_score(predLR, val_labels)\n",
    "accLR\n",
    "# first try 74,6%\n",
    "# 88,7% sa fsel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Confusion Matrix Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[20,  0,  0,  0,  0],\n",
       "       [ 0, 22,  1,  3,  0],\n",
       "       [ 0,  2, 14,  6,  0],\n",
       "       [ 0,  0,  6, 29,  0],\n",
       "       [ 0,  0,  0,  0, 39]])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confm_lr = metrics.confusion_matrix(val_labels, predLR)\n",
    "confm_lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
