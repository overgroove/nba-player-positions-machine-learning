{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from pandas import DataFrame\n",
    "import pandas as pd\n",
    "import scipy as sp\n",
    "from sklearn import metrics\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn import linear_model\n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reading files: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_data = sp.genfromtxt(\"data/train_data.txt\", delimiter=\"\\t\")\n",
    "\n",
    "test_data = sp.genfromtxt(\"data/test_data.txt\", delimiter=\"\\t\")\n",
    "\n",
    "val_data =  sp.genfromtxt(\"data/val_data.txt\", delimiter=\"\\t\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dimensions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(858L, 25L)\n",
      "(286L, 25L)\n",
      "(286L, 25L)\n"
     ]
    }
   ],
   "source": [
    "print(train_data.shape)\n",
    "print(test_data.shape)\n",
    "print(val_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(857L, 25L)\n",
      "(286L, 25L)\n",
      "(286L, 25L)\n"
     ]
    }
   ],
   "source": [
    "train_data = train_data[~np.isnan(train_data).any(axis=1)]\n",
    "test_data = test_data[~np.isnan(test_data).any(axis=1)]\n",
    "val_data = val_data[~np.isnan(val_data).any(axis=1)]\n",
    "print(train_data.shape)\n",
    "print(test_data.shape)\n",
    "print(val_data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Brisanje proba: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  4.79000000e+02,   8.10000000e+01,   2.29000000e+01,\n",
       "          4.08000000e+00,   7.65000000e+00,   5.34000000e-01,\n",
       "          1.00000000e-02,   4.00000000e-02,   1.76000000e-01,\n",
       "          2.72000000e+00,   3.45000000e+00,   7.88000000e-01,\n",
       "          1.98000000e+00,   3.03000000e+00,   5.01000000e+00,\n",
       "          6.80000000e-01,   4.30000000e-01,   4.10000000e-01,\n",
       "          2.39000000e+00,   1.22000000e+00,   1.08900000e+01,\n",
       "          8.00000000e+00,   3.40000000e+01,   1.12000000e+02,\n",
       "          2.06000000e+02]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  4.79000000e+02,   2.29000000e+01,   4.08000000e+00,\n",
       "         7.65000000e+00,   5.34000000e-01,   1.00000000e-02,\n",
       "         4.00000000e-02,   1.76000000e-01,   2.72000000e+00,\n",
       "         3.45000000e+00,   7.88000000e-01,   1.98000000e+00,\n",
       "         3.03000000e+00,   5.01000000e+00,   6.80000000e-01,\n",
       "         4.30000000e-01,   4.10000000e-01,   2.39000000e+00,\n",
       "         1.22000000e+00,   1.08900000e+01,   8.00000000e+00,\n",
       "         3.40000000e+01,   1.12000000e+02,   2.06000000e+02])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.delete(train_data[:1], 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def np_featuriser(train, test, val,feature_list):\n",
    "    \n",
    "    train = np.delete(train,feature_list,1)\n",
    "    test = np.delete(test,feature_list,1)\n",
    "    val = np.delete(val,feature_list,1)\n",
    "    \n",
    "    return train, test, val\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_all, test_all, val_all = np_featuriser(train_data, test_data, val_data,22)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(857L,)\n",
      "(286L,)\n",
      "(286L,)\n"
     ]
    }
   ],
   "source": [
    "train_labels = train_data[:,22]\n",
    "test_labels = test_data[:,22]\n",
    "val_labels = val_data[:,22]\n",
    "print(train_labels.shape)\n",
    "print(test_labels.shape)\n",
    "print(val_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "feature_list = [22]\n",
    "train_features_nb, test_features_nb, val_features_nb = np_featuriser(train_data, test_data, val_data, feature_list )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#train_features = np.delete(train_data, 22, 1)\n",
    "#test_features = np.delete(test_data, 22, 1)\n",
    "#val_features = np.delete(val_data,22,1)\n",
    "                          \n",
    "#train_features = np.delete(train_features, 21, 1)\n",
    "#test_features = np.delete(test_features, 21, 1)\n",
    "#val_features = np.delete(val_features,21,1)\n",
    "                          \n",
    "#print(train_features.shape)\n",
    "#print(test_features.shape)\n",
    "#print(val_features.shape)\n",
    "\n",
    "columns = {\"GP\":0, \"GS\":1, \"MIN\":2, \"FGM\":3,\"FGA\":4,\"FG%\":5,\"3PM\":6,\"3PA\":7,\"3P%\":8,\"FTM\":9,\"FTA\":10,\"FT%\":11,\"OFF\":12,\"DEF\":13,\n",
    "              \"TRB\":14,\"AST\":15,\"STL\":16,\"BLK\":17,\"PF\":18,\"TOV\":19,\"PTS\":20,\"YR\":21,\"POS\":22,\"W\":23,\"H\":24} \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Univariate feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  3.94708354e+00   3.31676009e+00   6.03282416e+00   6.24335941e+00\n",
      "   1.11107171e+01   1.36120482e+01   5.61392767e+01   6.44679563e+01\n",
      "   6.27045375e+01   3.40120889e+00   1.82896326e+00   1.73030171e+01\n",
      "   7.39240606e+01   2.74192593e+01   4.20483199e+01   7.59149900e+01\n",
      "   2.89898359e+01   5.92040295e+01   1.25166265e+01   1.07926258e+01\n",
      "   7.75632294e+00   1.39091934e-01   2.18662028e+02   2.87901072e+02]\n",
      "[  1.37098606e-02   1.15204854e-02   2.09545040e-02   2.16857804e-02\n",
      "   3.85921353e-02   4.72802970e-02   1.94995025e-01   2.23923989e-01\n",
      "   2.17798903e-01   1.18138112e-02   6.35274904e-03   6.01005651e-02\n",
      "   2.56768966e-01   9.52384761e-02   1.46051280e-01   2.63684291e-01\n",
      "   1.00693741e-01   2.05640185e-01   4.34754427e-02   3.74872721e-02\n",
      "   2.69409311e-02   4.83124057e-04   7.59504043e-01   1.00000000e+00]\n",
      "Most valuable features: \n",
      "6 0.194995025223 3PM\n",
      "7 0.223923988737 3PA\n",
      "8 0.217798902703 3P%\n",
      "12 0.256768966462 OFF\n",
      "15 0.263684291166 AST\n",
      "17 0.205640184623 BLK\n",
      "23 0.759504043217 W\n",
      "24 1.0 H\n",
      "[0, 1, 2, 3, 4, 5, 9, 10, 11, 13, 14, 16, 18, 19, 20, 21, 22]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_selection import SelectPercentile, f_classif\n",
    "selector = SelectPercentile(f_classif, percentile=10)\n",
    "X = train_features_nb\n",
    "y = train_labels\n",
    "#print X[:1]\n",
    "selector.fit(X, y)\n",
    "scores = -np.log10(selector.pvalues_)\n",
    "print scores\n",
    "scores /= scores.max()\n",
    "print scores\n",
    "\n",
    "#for i in scores:\n",
    "#scores\n",
    "\n",
    "print \"Most valuable features: \"\n",
    "remove = []\n",
    "for i in range(0,25):\n",
    "    remove.append(i)\n",
    "    \n",
    "j = 0\n",
    "for i in scores:\n",
    "    \n",
    "    if i>0.19:\n",
    "        print j, i, columns.keys()[columns.values().index(j)]\n",
    "        remove.remove(j)\n",
    "    if j == 21:\n",
    "        j = j+2\n",
    "    else:\n",
    "        j = j+1\n",
    "#for i in range(0,25)\n",
    "print remove"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#feature_list = [0, 1, 2, 3, 4, 5, 9, 10, 18, 19, 20, 21, 22]\n",
    "#train_features_nb, test_features_nb, val_features_nb = np_featuriser(train_data, test_data, val_data, feature_list )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "feature_list = [columns[\"GP\"],columns[\"GS\"],columns[\"MIN\"],columns[\"FG%\"],\n",
    "      columns[\"3P%\"],columns[\"FT%\"],columns[\"PTS\"],columns[\"YR\"],columns[\"POS\"],columns['3PM'],columns['FTM'],columns['FGM']]\n",
    "\n",
    "train_features_nb, test_features_nb, val_features_nb = np_featuriser(train_data, test_data, val_data, feature_list )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature selection with VarianceThreshold "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import VarianceThreshold\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def vt_fsel(train):\n",
    "    sel = VarianceThreshold(threshold=(.8 * (1 - .8)))\n",
    "    sel.fit_transform(train)\n",
    "    vt_list = sel.get_support()\n",
    "    l_vt = []\n",
    "    j = 0\n",
    "    for i in vt_list:\n",
    "        if i == False:\n",
    "            l_vt.append(j)\n",
    "            print \"%s. featue name: %s\" %(j, columns.keys()[columns.values().index(j)])\n",
    "        j = j+1\n",
    "    return l_vt    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5. featue name: FG%\n",
      "8. featue name: 3P%\n",
      "11. featue name: FT%\n",
      "16. featue name: STL\n"
     ]
    }
   ],
   "source": [
    "list_vt = vt_fsel(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#train_features1 = sel.fit_transform(train_features)\n",
    "#val_features1 = np.delete(val_features, 11, 1)\n",
    "#train_features1.shape\n",
    "#train_labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training features dimensions: \n",
      "(857L, 13L)\n",
      "Test features dimensions: \n",
      "(286L, 13L)\n",
      "Validation features dimensions: \n",
      "(286L, 13L)\n"
     ]
    }
   ],
   "source": [
    "print \"Training features dimensions: \"  \n",
    "print train_features_nb.shape\n",
    "print \"Test features dimensions: \" \n",
    "print test_features_nb.shape\n",
    "print \"Validation features dimensions: \"\n",
    "print val_features_nb.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Custom Accuracy function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def custom_acc(pred_labels, test_labels):\n",
    "    hit = 0\n",
    "    num = 0\n",
    "    j = 0\n",
    "    for i in pred_labels:\n",
    "        a = i\n",
    "        a = str(int(a))\n",
    "        b = test_labels[j]\n",
    "        b = str(int(b))\n",
    "        if a == b:\n",
    "            hit = hit+1\n",
    "        elif len(a) == 1 and len(b) == 2:\n",
    "            if a == b[0] or a == b[1]:\n",
    "                hit = hit+1\n",
    "        elif len(a) == 2 and len(b) == 1:\n",
    "            if a[0] == b or a[1] == b:\n",
    "                hit = hit+1\n",
    "        num = num+1\n",
    "        j = j+1\n",
    "    #print num\n",
    "    #print hit\n",
    "    return float(hit)/num\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# All Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "list_none = [22]\n",
    "list_domain = [columns[\"GP\"],columns[\"GS\"],columns[\"MIN\"],columns[\"FG%\"],\n",
    "      columns[\"3P%\"],columns[\"FT%\"],columns[\"PTS\"],columns[\"YR\"],columns[\"POS\"],columns['3PM'],columns['FTM'],columns['FGM']]\n",
    "list_uni = [0, 2, 4, 5, 7, 9, 10, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def print_metrics(name, accuracy, c_acc, conf_matrix):\n",
    "    print \"Feature selection: %s\\n\" %name\n",
    "    print \"Accuracy score: %s\\n\" %accuracy\n",
    "    print \"Custom Accuracy score: %s\\n\" %c_acc\n",
    "    print \"Confusion matrix:\"\n",
    "    print \"\\n%s\" %conf_matrix\n",
    "    print\"\\n\"\n",
    "    \n",
    "def clf(clf, tr, tr_labels, val, val_labels):\n",
    "        clf.fit(tr, tr_labels)\n",
    "        \n",
    "        pred = clf.predict(val)\n",
    "        \n",
    "        acc = metrics.accuracy_score(val_labels,pred)\n",
    "        c_acc = custom_acc(pred, val_labels)\n",
    "        conf = metrics.confusion_matrix(val_labels, pred)\n",
    "        \n",
    "        return acc, c_acc, conf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def clf_all(CLF, l_none, l_domain, l_uni, l_vt, train_all, test_all, val_all):\n",
    "    tr_none, ts_none, val_none = np_featuriser(train_all, test_all, val_all, l_none)\n",
    "    #print tr_none.shape\n",
    "    tr_domain, ts_domain, val_domain = np_featuriser(train_all, test_all, val_all, l_domain)\n",
    "    \n",
    "    tr_uni, ts_uni, val_uni = np_featuriser(train_all, test_all, val_all, l_uni)\n",
    "    \n",
    "    tr_vt, ts_vt, val_vt = np_featuriser(train_all, test_all, val_all, l_vt)\n",
    "    \n",
    "    #clfnb = GaussianNB()\n",
    "    #print \"Naive Bayes\\n\"\n",
    "    \n",
    "    acc_none, c_acc, conf_none = clf(CLF, tr_none, train_labels, val_none, val_labels)\n",
    "    print_metrics(\"None\", acc_none, c_acc, conf_none)\n",
    "    \n",
    "    acc_domain, c_acc, conf_domain = clf(CLF, tr_domain, train_labels, val_domain, val_labels)\n",
    "    print_metrics(\"Domain knowledge\", acc_domain, c_acc, conf_domain)\n",
    "\n",
    "    acc_uni,c_acc, conf_uni = clf(CLF, tr_uni, train_labels, val_uni, val_labels)\n",
    "    print_metrics(\"Univariate\", acc_uni, c_acc, conf_uni)\n",
    "    \n",
    "    acc_vt, c_acc, conf_vt = clf(CLF, tr_vt, train_labels, val_vt, val_labels)\n",
    "    print_metrics(\"Variance Threshold\", acc_vt, c_acc, conf_vt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature selection: None\n",
      "\n",
      "Accuracy score: 0.527972027972\n",
      "\n",
      "Custom Accuracy score: 0.741258741259\n",
      "\n",
      "Confusion matrix:\n",
      "\n",
      "[[10  0  0  0  0  4  0  0  0]\n",
      " [ 2 11  3  0  2 15  3  0  0]\n",
      " [ 0  1 10  0  0  1  4  4  0]\n",
      " [ 0  0  0 13 18  0  0  4  4]\n",
      " [ 0  0  0  3 36  0  0  0  8]\n",
      " [ 2  0  0  0  1 53  3  0  0]\n",
      " [ 0  1  2  0  0  1  1  0  0]\n",
      " [ 0  0  1  1 27  3  7 15  0]\n",
      " [ 0  0  0  0  8  0  0  2  2]]\n",
      "\n",
      "\n",
      "Feature selection: Domain knowledge\n",
      "\n",
      "Accuracy score: 0.583916083916\n",
      "\n",
      "Custom Accuracy score: 0.832167832168\n",
      "\n",
      "Confusion matrix:\n",
      "\n",
      "[[10  0  0  0  0  4  0  0  0]\n",
      " [ 1  8  3  0  0 23  1  0  0]\n",
      " [ 0  0 10  0  0  2  5  3  0]\n",
      " [ 0  0  0 14 11  0  0 11  3]\n",
      " [ 0  0  0  1 38  0  0  0  8]\n",
      " [ 2  1  0  0  0 55  1  0  0]\n",
      " [ 0  0  2  0  0  2  1  0  0]\n",
      " [ 0  0  1  1 12  5  6 29  0]\n",
      " [ 0  0  0  0  6  0  0  4  2]]\n",
      "\n",
      "\n",
      "Feature selection: Univariate\n",
      "\n",
      "Accuracy score: 0.381118881119\n",
      "\n",
      "Custom Accuracy score: 0.524475524476\n",
      "\n",
      "Confusion matrix:\n",
      "\n",
      "[[ 0  7  0  0  2  5  0  0  0]\n",
      " [ 0 10  4  0  2 19  0  1  0]\n",
      " [ 0  4  5  2  3  6  0  0  0]\n",
      " [ 0  0  1  6 27  2  1  2  0]\n",
      " [ 0  0  0  6 40  0  0  0  1]\n",
      " [ 0  0  0  0 15 41  1  2  0]\n",
      " [ 0  1  2  0  1  1  0  0  0]\n",
      " [ 0  1  0  1 37  8  0  7  0]\n",
      " [ 0  0  0  0 10  0  0  2  0]]\n",
      "\n",
      "\n",
      "Feature selection: Variance Threshold\n",
      "\n",
      "Accuracy score: 0.576923076923\n",
      "\n",
      "Custom Accuracy score: 0.804195804196\n",
      "\n",
      "Confusion matrix:\n",
      "\n",
      "[[12  0  0  0  0  2  0  0  0]\n",
      " [ 1  8  2  0  0 20  5  0  0]\n",
      " [ 0  0 10  0  0  1  6  3  0]\n",
      " [ 0  0  0 14 18  0  0  5  2]\n",
      " [ 0  0  0  2 38  0  0  0  7]\n",
      " [ 2  1  0  0  0 53  3  0  0]\n",
      " [ 0  1  2  0  0  1  1  0  0]\n",
      " [ 0  0  1  0 17  4  5 27  0]\n",
      " [ 0  0  0  0  8  0  0  2  2]]\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clfnb = GaussianNB()\n",
    "clf_all(clfnb, list_none, list_domain, list_uni, list_vt, train_all, test_all, val_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature selection: None\n",
      "\n",
      "Accuracy score: 0.618881118881\n",
      "\n",
      "Custom Accuracy score: 0.902097902098\n",
      "\n",
      "Confusion matrix:\n",
      "\n",
      "[[ 7  0  0  0  0  7  0  0  0]\n",
      " [ 0 14  0  0  0 21  1  0  0]\n",
      " [ 0  2  9  0  0  1  3  5  0]\n",
      " [ 0  0  0 17  5  0  0 14  3]\n",
      " [ 0  0  0  1 42  0  0  3  1]\n",
      " [ 3  3  2  0  0 51  0  0  0]\n",
      " [ 0  2  1  0  0  2  0  0  0]\n",
      " [ 0  0  6  4  3  2  2 37  0]\n",
      " [ 0  0  0  2  5  0  0  5  0]]\n",
      "\n",
      "\n",
      "Feature selection: Domain knowledge\n",
      "\n",
      "Accuracy score: 0.583916083916\n",
      "\n",
      "Custom Accuracy score: 0.877622377622\n",
      "\n",
      "Confusion matrix:\n",
      "\n",
      "[[ 8  0  0  0  0  6  0  0  0]\n",
      " [ 0  8  1  0  0 26  1  0  0]\n",
      " [ 0  1  9  0  0  2  4  4  0]\n",
      " [ 0  0  1 11  7  0  0 16  4]\n",
      " [ 0  0  0  3 42  0  0  1  1]\n",
      " [ 2  2  0  0  0 53  1  1  0]\n",
      " [ 0  2  1  0  0  2  0  0  0]\n",
      " [ 0  0  3  4  2  2  6 35  2]\n",
      " [ 0  0  0  3  5  0  0  3  1]]\n",
      "\n",
      "\n",
      "Feature selection: Univariate\n",
      "\n",
      "Accuracy score: 0.405594405594\n",
      "\n",
      "Custom Accuracy score: 0.629370629371\n",
      "\n",
      "Confusion matrix:\n",
      "\n",
      "[[ 0  0  1  0  0 13  0  0  0]\n",
      " [ 0  1  2  0  0 28  0  5  0]\n",
      " [ 0  0  2  1  2 10  0  5  0]\n",
      " [ 0  0  0  3 28  1  0  7  0]\n",
      " [ 0  0  0  0 44  2  0  1  0]\n",
      " [ 0  0  0  0  3 50  0  6  0]\n",
      " [ 0  0  1  0  1  1  0  2  0]\n",
      " [ 0  0  0  1 27 10  0 16  0]\n",
      " [ 0  0  0  0  9  0  0  3  0]]\n",
      "\n",
      "\n",
      "Feature selection: Variance Threshold\n",
      "\n",
      "Accuracy score: 0.618881118881\n",
      "\n",
      "Custom Accuracy score: 0.905594405594\n",
      "\n",
      "Confusion matrix:\n",
      "\n",
      "[[ 9  0  0  0  0  5  0  0  0]\n",
      " [ 0 14  0  0  0 21  1  0  0]\n",
      " [ 1  1 11  0  0  0  2  5  0]\n",
      " [ 0  0  0 18  5  0  0 14  2]\n",
      " [ 0  0  0  3 42  0  0  1  1]\n",
      " [ 6  2  3  0  0 47  1  0  0]\n",
      " [ 0  1  1  0  0  2  1  0  0]\n",
      " [ 0  0 10  5  1  2  2 33  1]\n",
      " [ 0  0  0  3  3  0  0  4  2]]\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "svm = SVC()\n",
    "svm.set_params(kernel='linear')\n",
    "clf_all(svm, list_none, list_domain, list_uni, list_vt, train_all, test_all, val_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature selection: None\n",
      "\n",
      "Accuracy score: 0.548951048951\n",
      "\n",
      "Custom Accuracy score: 0.79020979021\n",
      "\n",
      "Confusion matrix:\n",
      "\n",
      "[[ 6  0  0  0  0  8  0  0  0]\n",
      " [ 1  8  3  0  0 20  0  4  0]\n",
      " [ 0  2  4  4  0  2  0  8  0]\n",
      " [ 0  0  0 14 12  0  0 12  1]\n",
      " [ 0  0  0  1 44  0  0  1  1]\n",
      " [ 8  0  0  0  0 43  1  7  0]\n",
      " [ 0  1  0  0  0  2  0  2  0]\n",
      " [ 0  0  0  4  5  6  1 38  0]\n",
      " [ 0  0  0  1  5  0  0  6  0]]\n",
      "\n",
      "\n",
      "Feature selection: Domain knowledge\n",
      "\n",
      "Accuracy score: 0.555944055944\n",
      "\n",
      "Custom Accuracy score: 0.818181818182\n",
      "\n",
      "Confusion matrix:\n",
      "\n",
      "[[ 5  0  0  0  0  9  0  0  0]\n",
      " [ 0  5  1  0  0 25  1  4  0]\n",
      " [ 0  2  1  2  0  3  0 12  0]\n",
      " [ 0  0  0 15 12  0  0 12  0]\n",
      " [ 0  0  0  0 43  0  0  3  1]\n",
      " [ 3  1  0  0  0 51  0  4  0]\n",
      " [ 0  0  0  0  0  2  0  3  0]\n",
      " [ 0  0  0  3  5  6  1 39  0]\n",
      " [ 0  0  0  2  6  0  0  4  0]]\n",
      "\n",
      "\n",
      "Feature selection: Univariate\n",
      "\n",
      "Accuracy score: 0.409090909091\n",
      "\n",
      "Custom Accuracy score: 0.622377622378\n",
      "\n",
      "Confusion matrix:\n",
      "\n",
      "[[ 1  0  1  0  0 12  0  0  0]\n",
      " [ 1  1  1  0  0 25  0  8  0]\n",
      " [ 0  0  3  1  2 10  0  4  0]\n",
      " [ 0  0  0  4 26  1  0  8  0]\n",
      " [ 0  0  0  3 40  1  0  3  0]\n",
      " [ 0  0  0  0  4 48  1  6  0]\n",
      " [ 0  0  2  0  0  1  0  2  0]\n",
      " [ 0  0  0  2 23  9  0 20  0]\n",
      " [ 0  0  0  0  8  0  0  4  0]]\n",
      "\n",
      "\n",
      "Feature selection: Variance Threshold\n",
      "\n",
      "Accuracy score: 0.559440559441\n",
      "\n",
      "Custom Accuracy score: 0.77972027972\n",
      "\n",
      "Confusion matrix:\n",
      "\n",
      "[[ 7  0  0  0  0  7  0  0  0]\n",
      " [ 0  7  3  1  0 21  0  4  0]\n",
      " [ 1  2  2  3  0  5  0  7  0]\n",
      " [ 0  0  0 15 10  0  0 11  3]\n",
      " [ 0  0  0  1 42  0  0  3  1]\n",
      " [ 6  0  0  0  0 46  1  6  0]\n",
      " [ 0  1  0  0  0  2  0  2  0]\n",
      " [ 0  0  0  2  4  7  1 40  0]\n",
      " [ 0  0  0  1  3  0  0  7  1]]\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "logreg = linear_model.LogisticRegression(C=1e5)\n",
    "clf_all(logreg, list_none, list_domain, list_uni, list_vt, train_all, test_all, val_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
