{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from pandas import DataFrame\n",
    "import pandas as pd\n",
    "import scipy as sp\n",
    "from sklearn import metrics\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn import linear_model\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.feature_selection import VarianceThreshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def read_data(folder, name1, name2, name3):\n",
    "    loc = \"%s/%s.txt\" %(folder, name1)\n",
    "    train_set = pd.read_csv(loc, sep=\"\\t\")\n",
    "    print \"Training set has %s rows and %s coumns\" %(train_set.shape[0], train_set.shape[1])\n",
    "    loc = \"%s/%s.txt\" %(folder, name2)\n",
    "    test_set = pd.read_csv(loc, sep=\"\\t\")\n",
    "    print \"Testing set has %s rows and %s coumns\" %(test_set.shape[0], test_set.shape[1])\n",
    "    loc = \"%s/%s.txt\" %(folder, name3)\n",
    "    val_set = pd.read_csv(loc, sep=\"\\t\")\n",
    "    print \"Validation set has %s rows and %s coumns\" %(val_set.shape[0], val_set.shape[1])\n",
    "    return train_set, test_set, val_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set has 762 rows and 25 coumns\n",
      "Testing set has 254 rows and 25 coumns\n",
      "Validation set has 253 rows and 25 coumns\n"
     ]
    }
   ],
   "source": [
    "train_set, test_set, val_set = read_data(\"data3\", \"train_data\", \"test_data\", \"valid_data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_set_nb = sp.genfromtxt(\"data3/train_data.txt\", delimiter=\"\\t\")\n",
    "test_set_nb = test_set.values\n",
    "val_set_nb = val_set.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def np_cleaner(train, test, val):\n",
    "    train = train[~np.isnan(train).any(axis=1)]\n",
    "    print \"Training set has %s rows and %s coumns\" %(train.shape[0], train.shape[1])\n",
    "    test = test[~np.isnan(test).any(axis=1)]\n",
    "    print \"Testing set has %s rows and %s coumns\" %(test.shape[0], test.shape[1])\n",
    "    val = val[~np.isnan(val).any(axis=1)]\n",
    "    print \"Validation set has %s rows and %s coumns\" %(val.shape[0], val.shape[1])\n",
    "    return train, test, val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_data = train_set_nb[~np.isnan(train_set_nb).any(axis=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set has 761 rows and 25 coumns\n",
      "Testing set has 254 rows and 25 coumns\n",
      "Validation set has 253 rows and 25 coumns\n"
     ]
    }
   ],
   "source": [
    "train_set_nb, test_set_nb, val_set_nb = np_cleaner(train_data, test_set_nb, val_set_nb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set has 761 rows and 25 coumns\n",
      "Testing set has 254 rows and 25 coumns\n",
      "Validation set has 253 rows and 25 coumns\n"
     ]
    }
   ],
   "source": [
    "train_all, test_all, val_all = np_cleaner(train_data, test_set_nb, val_set_nb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([u'GP', u'GS', u'MIN', u'FGM', u'FGA', u'FG%', u'3PM', u'3PA', u'3P%',\n",
       "       u'FTM', u'FTA', u'FT%', u'OFF', u'DEF', u'TRB', u'AST', u'STL', u'BLK',\n",
       "       u'PF', u'TOV', u'PTS', u'YR', u'POS', u'W', u'H'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_set.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "columns = {\"GP\":0, \"GS\":1, \"MIN\":2, \"FGM\":3,\"FGA\":4,\"FG%\":5,\"3PM\":6,\"3PA\":7,\"3P%\":8,\"FTM\":9,\"FTA\":10,\"FT%\":11,\"OFF\":12,\"DEF\":13,\n",
    "              \"TRB\":14,\"AST\":15,\"STL\":16,\"BLK\":17,\"PF\":18,\"TOV\":19,\"PTS\":20,\"YR\":21,\"POS\":22,\"W\":23,\"H\":24} "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def np_labeliser(train, test, val, col):\n",
    "    train = train[:,col]\n",
    "    test = test[:,col]\n",
    "    val = val[:,col]\n",
    "    return train, test, val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_labels, test_labels, val_labels = np_labeliser(train_set_nb, test_set_nb, val_set_nb, 22)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def np_featuriser(train, test, val,feature_list):\n",
    "    \n",
    "    train = np.delete(train,feature_list,1)\n",
    "    test = np.delete(test,feature_list,1)\n",
    "    val = np.delete(val,feature_list,1)\n",
    "    \n",
    "    return train, test, val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "feature_list = [22]\n",
    "train_features_nb, test_features_nb, val_features_nb = np_featuriser(train_set_nb, test_set_nb, val_set_nb, feature_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def vt_fsel(train):\n",
    "    sel = VarianceThreshold(threshold=(.8 * (1 - .8)))\n",
    "    sel.fit_transform(train)\n",
    "    vt_list = sel.get_support()\n",
    "    l_vt = []\n",
    "    j = 0\n",
    "    for i in vt_list:\n",
    "        if i == False:\n",
    "            l_vt.append(j)\n",
    "            print \"%s. featue name: %s\" %(j, columns.keys()[columns.values().index(j)])\n",
    "        j = j+1\n",
    "    return l_vt    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5. featue name: FG%\n",
      "8. featue name: 3P%\n",
      "11. featue name: FT%\n"
     ]
    }
   ],
   "source": [
    "list_vt = vt_fsel(train_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  3.45901528e-03   9.43715652e-04   2.45842793e-02   2.19370568e-02\n",
      "   4.63643829e-02   5.25611868e-02   2.00699275e-01   2.29780197e-01\n",
      "   2.40903355e-01   8.79857809e-03   1.63272775e-03   7.73922378e-02\n",
      "   2.57437639e-01   8.75295104e-02   1.41504560e-01   2.47296954e-01\n",
      "   1.10267123e-01   2.40587521e-01   5.15644450e-02   3.82173977e-02\n",
      "   2.89519767e-02   2.90464311e-03   7.86685640e-01   1.00000000e+00]\n",
      "Most valuable features: \n",
      "6 0.200699275139 3PM\n",
      "7 0.229780197251 3PA\n",
      "8 0.240903355016 3P%\n",
      "12 0.257437639275 OFF\n",
      "15 0.247296953898 AST\n",
      "17 0.24058752131 BLK\n",
      "23 0.786685640148 W\n",
      "24 1.0 H\n",
      "[0, 1, 2, 3, 4, 5, 9, 10, 11, 13, 14, 16, 18, 19, 20, 21, 22]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_selection import SelectPercentile, f_classif\n",
    "selector = SelectPercentile(f_classif, percentile=10)\n",
    "X = train_features_nb\n",
    "y = train_labels\n",
    "#print X[:1]\n",
    "selector.fit(X, y)\n",
    "scores = -np.log10(selector.pvalues_)\n",
    "#print scores\n",
    "scores /= scores.max()\n",
    "print scores\n",
    "\n",
    "#for i in scores:\n",
    "#scores\n",
    "\n",
    "print \"Most valuable features: \"\n",
    "remove = []\n",
    "for i in range(0,25):\n",
    "    remove.append(i)\n",
    "    \n",
    "j = 0\n",
    "for i in scores:\n",
    "    \n",
    "    if i>0.20:\n",
    "        print j, i, columns.keys()[columns.values().index(j)]\n",
    "        remove.remove(j)\n",
    "    if j == 21:\n",
    "        j = j+2\n",
    "    else:\n",
    "        j = j+1\n",
    "#for i in range(0,25)\n",
    "print remove\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#feature_list = [0, 1, 2, 3, 4, 5, 9, 10, 11, 18, 19, 20, 21, 22]\n",
    "#train_features_nb, test_features_nb, val_features_nb = np_featuriser(train_set_nb, test_set_nb, val_set_nb, feature_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#feature_list = [columns[\"GP\"],columns[\"GS\"],columns[\"MIN\"],columns[\"FG%\"],\n",
    "#      columns[\"3P%\"],columns[\"FT%\"],columns[\"PTS\"],columns[\"YR\"],columns[\"POS\"],columns['3PM'],columns['FTM'],columns['FGM']]\n",
    "\n",
    "#train_features_nb, test_features_nb, val_features_nb = np_featuriser(train_set_nb, test_set_nb, val_set_nb, feature_list )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ALL Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "list_none = [22]\n",
    "list_domain = [columns[\"GP\"],columns[\"GS\"],columns[\"MIN\"],columns[\"FG%\"],\n",
    "      columns[\"3P%\"],columns[\"FT%\"],columns[\"PTS\"],columns[\"YR\"],columns[\"POS\"],columns['3PM'],columns['FTM'],columns['FGM']]\n",
    "list_uni = [0, 1, 2, 3, 4, 5, 9, 10, 11, 13, 14, 16, 18, 19, 20, 21, 22]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def print_metrics(name, accuracy, conf_matrix):\n",
    "    print \"Feature selection: %s\\n\" %name\n",
    "    print \"Accuracy score: %s\\n\" %accuracy\n",
    "    print \"Confusion matrix:\"\n",
    "    print \"\\n%s\" %conf_matrix\n",
    "    print\"\\n\"\n",
    "    \n",
    "def clf(clf, tr, tr_labels, val, val_labels):\n",
    "        clf.fit(tr, tr_labels)\n",
    "        \n",
    "        pred = clf.predict(val)\n",
    "        \n",
    "        acc = metrics.accuracy_score(val_labels,pred)\n",
    "        conf = metrics.confusion_matrix(val_labels, pred)\n",
    "        \n",
    "        return acc, conf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def clf_all(CLF, l_none, l_domain, l_uni, l_vt, train_all, test_all, val_all):\n",
    "    tr_none, ts_none, val_none = np_featuriser(train_all, test_all, val_all, l_none)\n",
    "    print tr_none.shape\n",
    "    tr_domain, ts_domain, val_domain = np_featuriser(train_all, test_all, val_all, l_domain)\n",
    "    \n",
    "    tr_uni, ts_uni, val_uni = np_featuriser(train_all, test_all, val_all, l_uni)\n",
    "    \n",
    "    tr_vt, ts_vt, val_vt = np_featuriser(train_all, test_all, val_all, l_vt)\n",
    "    \n",
    "    #clfnb = GaussianNB()\n",
    "    #print \"Naive Bayes\\n\"\n",
    "    \n",
    "    acc_none, conf_none = clf(CLF, tr_none, train_labels, val_none, val_labels)\n",
    "    print_metrics(\"None\", acc_none, conf_none)\n",
    "    \n",
    "    acc_domain, conf_domain = clf(CLF, tr_domain, train_labels, val_domain, val_labels)\n",
    "    print_metrics(\"Domain knowledge\", acc_domain, conf_domain)\n",
    "\n",
    "    acc_uni, conf_uni = clf(CLF, tr_uni, train_labels, val_uni, val_labels)\n",
    "    print_metrics(\"Univariate\", acc_uni, conf_uni)\n",
    "    \n",
    "    acc_vt, conf_vt = clf(CLF, tr_vt, train_labels, val_vt, val_labels)\n",
    "    print_metrics(\"Variance Threshold\", acc_vt, conf_vt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(761L, 24L)\n",
      "Feature selection: None\n",
      "\n",
      "Accuracy score: 0.735177865613\n",
      "\n",
      "Confusion matrix:\n",
      "\n",
      "[[90  5  3]\n",
      " [12 63 42]\n",
      " [ 0  5 33]]\n",
      "\n",
      "\n",
      "Feature selection: Domain knowledge\n",
      "\n",
      "Accuracy score: 0.790513833992\n",
      "\n",
      "Confusion matrix:\n",
      "\n",
      "[[93  5  0]\n",
      " [18 74 25]\n",
      " [ 0  5 33]]\n",
      "\n",
      "\n",
      "Feature selection: Univariate\n",
      "\n",
      "Accuracy score: 0.786561264822\n",
      "\n",
      "Confusion matrix:\n",
      "\n",
      "[[90  8  0]\n",
      " [ 5 75 37]\n",
      " [ 0  4 34]]\n",
      "\n",
      "\n",
      "Feature selection: Variance Threshold\n",
      "\n",
      "Accuracy score: 1.0\n",
      "\n",
      "Confusion matrix:\n",
      "\n",
      "[[ 98   0   0]\n",
      " [  0 117   0]\n",
      " [  0   0  38]]\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clfnb = GaussianNB()\n",
    "clf_all(clfnb, list_none, list_domain, list_uni, list_vt, train_all, test_all, val_all)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(761L, 24L)\n",
      "Feature selection: None\n",
      "\n",
      "Accuracy score: 0.893280632411\n",
      "\n",
      "Confusion matrix:\n",
      "\n",
      "[[ 93   5   0]\n",
      " [  6 105   6]\n",
      " [  0  10  28]]\n",
      "\n",
      "\n",
      "Feature selection: Domain knowledge\n",
      "\n",
      "Accuracy score: 0.893280632411\n",
      "\n",
      "Confusion matrix:\n",
      "\n",
      "[[ 93   5   0]\n",
      " [  7 103   7]\n",
      " [  0   8  30]]\n",
      "\n",
      "\n",
      "Feature selection: Univariate\n",
      "\n",
      "Accuracy score: 0.901185770751\n",
      "\n",
      "Confusion matrix:\n",
      "\n",
      "[[ 93   5   0]\n",
      " [  4 105   8]\n",
      " [  0   8  30]]\n",
      "\n",
      "\n",
      "Feature selection: Variance Threshold\n",
      "\n",
      "Accuracy score: 1.0\n",
      "\n",
      "Confusion matrix:\n",
      "\n",
      "[[ 98   0   0]\n",
      " [  0 117   0]\n",
      " [  0   0  38]]\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "svm = SVC()\n",
    "svm.set_params(kernel='linear')\n",
    "clf_all(svm, list_none, list_domain, list_uni, list_vt, train_all, test_all, val_all)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(761L, 24L)\n",
      "Feature selection: None\n",
      "\n",
      "Accuracy score: 0.849802371542\n",
      "\n",
      "Confusion matrix:\n",
      "\n",
      "[[ 89   9   0]\n",
      " [  8 100   9]\n",
      " [  0  12  26]]\n",
      "\n",
      "\n",
      "Feature selection: Domain knowledge\n",
      "\n",
      "Accuracy score: 0.877470355731\n",
      "\n",
      "Confusion matrix:\n",
      "\n",
      "[[ 91   7   0]\n",
      " [  6 104   7]\n",
      " [  0  11  27]]\n",
      "\n",
      "\n",
      "Feature selection: Univariate\n",
      "\n",
      "Accuracy score: 0.857707509881\n",
      "\n",
      "Confusion matrix:\n",
      "\n",
      "[[ 89   9   0]\n",
      " [  7 101   9]\n",
      " [  0  11  27]]\n",
      "\n",
      "\n",
      "Feature selection: Variance Threshold\n",
      "\n",
      "Accuracy score: 1.0\n",
      "\n",
      "Confusion matrix:\n",
      "\n",
      "[[ 98   0   0]\n",
      " [  0 117   0]\n",
      " [  0   0  38]]\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "logreg = linear_model.LogisticRegression(C=1e5)\n",
    "clf_all(logreg, list_none, list_domain, list_uni, list_vt, train_all, test_all, val_all)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
