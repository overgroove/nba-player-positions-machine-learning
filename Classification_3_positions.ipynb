{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from pandas import DataFrame\n",
    "import pandas as pd\n",
    "import scipy as sp\n",
    "from sklearn import metrics\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn import linear_model\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_selection import SelectPercentile, f_classif\n",
    "from sklearn import cross_validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.set_printoptions(precision=5,suppress=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#def read_data(folder, name1, name2, name3):\n",
    "#    loc = \"%s/%s.txt\" %(folder, name1)\n",
    "#    train_set = pd.read_csv(loc, sep=\"\\t\")\n",
    "#    print \"Training set has %s rows and %s coumns\" %(train_set.shape[0], train_set.shape[1])\n",
    "#    loc = \"%s/%s.txt\" %(folder, name2)\n",
    "#    test_set = pd.read_csv(loc, sep=\"\\t\")\n",
    "#    print \"Testing set has %s rows and %s coumns\" %(test_set.shape[0], test_set.shape[1])\n",
    "#    loc = \"%s/%s.txt\" %(folder, name3)\n",
    "#    val_set = pd.read_csv(loc, sep=\"\\t\")\n",
    "#    print \"Validation set has %s rows and %s coumns\" %(val_set.shape[0], val_set.shape[1])\n",
    "#    return train_set, test_set, val_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dataset = sp.genfromtxt(\"data3/cleaned.txt\", delimiter=\"\\t\")\n",
    "#np.isnan(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1269L, 27L)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#train_set, test_set, val_set = read_data(\"data3\", \"train_data\", \"test_data\", \"valid_data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1269L, 25L)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = np.delete(dataset,[0,26],1)\n",
    "dataset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  52.       2.       8.3      1.31     3.08     0.425    0.       0.       0.\n",
      "    0.5      0.87     0.578    0.6      1.25     1.85     0.27     0.17\n",
      "    0.35     1.12     0.42     3.12     2.       2.     104.     208.   ]\n"
     ]
    }
   ],
   "source": [
    "print dataset[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1268L, 25L)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = dataset[~np.isnan(dataset).any(axis=1)]\n",
    "dataset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "columns = {\"GP\":0, \"GS\":1, \"MIN\":2, \"FGM\":3,\"FGA\":4,\"FG%\":5,\"3PM\":6,\"3PA\":7,\"3P%\":8,\"FTM\":9,\"FTA\":10,\"FT%\":11,\"OFF\":12,\"DEF\":13,\n",
    "              \"TRB\":14,\"AST\":15,\"STL\":16,\"BLK\":17,\"PF\":18,\"TOV\":19,\"PTS\":20,\"YR\":21,\"W\":22,\"H\":23} "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def np_labeliser(data,col):\n",
    "    labels = data[:,col]\n",
    "    return labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 2.,  1.,  2.,  2.,  2.,  3.,  2.,  2.,  3.,  1.])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = np_labeliser(dataset,22)\n",
    "labels[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def np_featuriser(dataset, feature_list):\n",
    "    \n",
    "    features = np.delete(dataset,feature_list,1)\n",
    "    #test = np.delete(test,feature_list,1)\n",
    "    #val = np.delete(val,feature_list,1)\n",
    "    \n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25\n",
      "24\n"
     ]
    }
   ],
   "source": [
    "feature_list = [22]\n",
    "#np.set_printoptions(precision=4)\n",
    "print len(dataset[0])\n",
    "#train_features_nb, test_features_nb, val_features_nb = np_featuriser(train_set_nb, test_set_nb, val_set_nb, feature_list)\n",
    "features = np_featuriser(dataset, feature_list)\n",
    "print len(features[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def vt_fsel(feature_set):\n",
    "    sel = VarianceThreshold(threshold=(.8 * (1 - .8)))\n",
    "    sel.fit_transform(feature_set)\n",
    "    vt_list = sel.get_support()\n",
    "    l_vt = []\n",
    "    j = 0\n",
    "    for i in vt_list:\n",
    "        if i == False:\n",
    "            l_vt.append(j)\n",
    "            print \"%s. feature name: %s\" %(j, columns.keys()[columns.values().index(j)])\n",
    "        j = j+1\n",
    "    return l_vt    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5. feature name: FG%\n",
      "8. feature name: 3P%\n",
      "11. feature name: FT%\n"
     ]
    }
   ],
   "source": [
    "list_vt = vt_fsel(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1268L, 21L)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_vt = np_featuriser(features, list_vt)\n",
    "\n",
    "features_vt.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def sup_features(usp_list,x):\n",
    "    remove = []\n",
    "    j = 0\n",
    "    for i in usp_list:\n",
    "        if i == False:\n",
    "            remove.append(j)\n",
    "            if x==\"vt\":\n",
    "                print \"%s. feature name: %s\" %(j, columns.keys()[columns.values().index(j)])\n",
    "        elif x == \"uni\":\n",
    "            print \"%s. feature name: %s\" %(j, columns.keys()[columns.values().index(j)])\n",
    "        j = j+1  \n",
    "\n",
    "    return remove\n",
    "#sup_features(support, \"uni\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def feature_selection(clf, features, labels, domain):\n",
    "    none = features\n",
    "    #print none[0]\n",
    "    domain = np_featuriser(features, domain)\n",
    "    #print domain[0]\n",
    "    clf = Pipeline([('feature_selection',SelectPercentile(f_classif, percentile=20)),\n",
    "  ('classification', clf)])\n",
    "    clf.fit(features, labels)\n",
    "    print \"\\nUnivariate - valuable features \\n\"\n",
    "    uni = sup_features(clf.named_steps['feature_selection'].get_support(),\"uni\")\n",
    "    uni = np_featuriser(features, uni)\n",
    "    #print uni[0]\n",
    "    clf = Pipeline([('feature_selection',VarianceThreshold(threshold=(.8 * (1 - .8)))),\n",
    "  ('classification', clf)])\n",
    "    clf.fit(features, labels)\n",
    "    print \"\\nVariance Threshold - removed \\n\"\n",
    "    v_th = sup_features(clf.named_steps['feature_selection'].get_support(), \"vt\")\n",
    "    #print v_th[0]\n",
    "    v_th = np_featuriser(features, v_th)\n",
    "    return none, domain, uni, v_th  \n",
    "#clf = GaussianNB()\n",
    "#svm = SVC()\n",
    "#svm.set_params(kernel='linear')\n",
    "#clf = Pipeline([('feature_selection',VarianceThreshold(threshold=(.8 * (1 - .8)))),\n",
    " # ('classification', svm)])\n",
    "#clf.fit(features, labels)\n",
    "#support = clf.named_steps['feature_selection'].get_support()\n",
    "#print support\n",
    "#p = clf.predict(features)\n",
    "#acc = metrics.accuracy_score(labels,p)\n",
    "#conf = metrics.confusion_matrix(labels, p)\n",
    "#print acc\n",
    "#print conf\n",
    "domain = [columns[\"GP\"],columns[\"GS\"],columns[\"MIN\"],columns[\"FG%\"],\n",
    "     columns[\"3P%\"],columns[\"FT%\"],columns[\"PTS\"],columns[\"YR\"],columns['3PM'],columns['FTM'],columns['FGM']]\n",
    "#none, domain, uni, vth = feature_selection(clf, features, labels, domain)\n",
    "#print none.shape,domain.shape,uni.shape,vth.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def cross_val(clf, f, l, name):\n",
    "    print \"\\nFeature selection: %s\" %name\n",
    "    scores = cross_validation.cross_val_score(clf, f, l, cv=10)\n",
    "    print(\"Accuracy: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def clf_all(clf, features, labels, domain):\n",
    "    none, domain, uni, vth = feature_selection(clf, features, labels, domain)\n",
    "    \n",
    "    cross_val(clf, none, labels, \"None\")\n",
    "    print \"Number of features left: %s\" %none.shape[1]\n",
    "    cross_val(clf, domain, labels, \"Domain\")\n",
    "    print \"Number of features left: %s\" %domain.shape[1]\n",
    "    cross_val(clf, uni, labels, \"Univariate\")\n",
    "    print \"Number of features left: %s\" %uni.shape[1]\n",
    "    cross_val(clf, vth, labels, \"Variance Threshold\")\n",
    "    print \"Number of features left: %s\" %vth.shape[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ALL Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#def print_metrics(name, accuracy, conf_matrix):\n",
    "#    print \"Feature selection: %s\\n\" %name\n",
    "#   print \"Accuracy score: %s\\n\" %accuracy\n",
    " #   print \"Confusion matrix:\"\n",
    "#  print \"\\n%s\" %conf_matrix\n",
    "  # print\"\\n\"\n",
    "    \n",
    "#def clf(clf, tr, tr_labels, val, val_labels):\n",
    "#        clf.fit(tr, tr_labels)\n",
    "#        \n",
    "#        pred = clf.predict(val)\n",
    "#        \n",
    "#        acc = metrics.accuracy_score(val_labels,pred)\n",
    "#        conf = metrics.confusion_matrix(val_labels, pred)\n",
    "        \n",
    "#        return acc, conf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#def clf_all(CLF, l_none, l_domain, l_uni, l_vt, train_all, test_all, val_all):\n",
    "#    tr_none, ts_none, val_none = np_featuriser(train_all, test_all, val_all, l_none)\n",
    "#    print tr_none.shape\n",
    "#    tr_domain, ts_domain, val_domain = np_featuriser(train_all, test_all, val_all, l_domain)\n",
    "#    \n",
    "#    tr_uni, ts_uni, val_uni = np_featuriser(train_all, test_all, val_all, l_uni)\n",
    "#    \n",
    "#    tr_vt, ts_vt, val_vt = np_featuriser(train_all, test_all, val_all, l_vt)\n",
    "    \n",
    "    #clfnb = GaussianNB()\n",
    "    #print \"Naive Bayes\\n\"\n",
    "    \n",
    "#    acc_none, conf_none = clf(CLF, tr_none, train_labels, val_none, test_labels)\n",
    "#    print_metrics(\"None\", acc_none, conf_none)\n",
    "    \n",
    "#    acc_domain, conf_domain = clf(CLF, tr_domain, train_labels, val_domain, val_labels)\n",
    "#    print_metrics(\"Domain knowledge\", acc_domain, conf_domain)\n",
    "\n",
    "#    acc_uni, conf_uni = clf(CLF, tr_uni, train_labels, val_uni, val_labels)\n",
    "#    print_metrics(\"Univariate\", acc_uni, conf_uni)\n",
    "    \n",
    "#    acc_vt, conf_vt = clf(CLF, tr_vt, train_labels, val_vt, val_labels)\n",
    "#    print_metrics(\"Variance Threshold\", acc_vt, conf_vt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Univariate - valuable features \n",
      "\n",
      "12. feature name: OFF\n",
      "15. feature name: AST\n",
      "17. feature name: BLK\n",
      "22. feature name: W\n",
      "23. feature name: H\n",
      "\n",
      "Variance Threshold - removed \n",
      "\n",
      "5. feature name: FG%\n",
      "8. feature name: 3P%\n",
      "11. feature name: FT%\n",
      "\n",
      "Feature selection: None\n",
      "Accuracy: 0.81 (+/- 0.08)\n",
      "Number of features left: 24\n",
      "\n",
      "Feature selection: Domain\n",
      "Accuracy: 0.87 (+/- 0.07)\n",
      "Number of features left: 13\n",
      "\n",
      "Feature selection: Univariate\n",
      "Accuracy: 0.89 (+/- 0.04)\n",
      "Number of features left: 5\n",
      "\n",
      "Feature selection: Variance Threshold\n",
      "Accuracy: 0.82 (+/- 0.07)\n",
      "Number of features left: 21\n"
     ]
    }
   ],
   "source": [
    "clf_all(GaussianNB(), features, labels, domain) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Univariate - valuable features \n",
      "\n",
      "12. feature name: OFF\n",
      "15. feature name: AST\n",
      "17. feature name: BLK\n",
      "22. feature name: W\n",
      "23. feature name: H\n",
      "\n",
      "Variance Threshold - removed \n",
      "\n",
      "5. feature name: FG%\n",
      "8. feature name: 3P%\n",
      "11. feature name: FT%\n",
      "\n",
      "Feature selection: None\n",
      "Accuracy: 0.90 (+/- 0.04)\n",
      "Number of features left: 24\n",
      "\n",
      "Feature selection: Domain\n",
      "Accuracy: 0.91 (+/- 0.05)\n",
      "Number of features left: 13\n",
      "\n",
      "Feature selection: Univariate\n",
      "Accuracy: 0.91 (+/- 0.04)\n",
      "Number of features left: 5\n",
      "\n",
      "Feature selection: Variance Threshold\n",
      "Accuracy: 0.90 (+/- 0.04)\n",
      "Number of features left: 21\n"
     ]
    }
   ],
   "source": [
    "svm = SVC()\n",
    "svm = svm.set_params(kernel='linear')\n",
    "clf_all(svm, features, labels, domain) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Univariate - valuable features \n",
      "\n",
      "12. feature name: OFF\n",
      "15. feature name: AST\n",
      "17. feature name: BLK\n",
      "22. feature name: W\n",
      "23. feature name: H\n",
      "\n",
      "Variance Threshold - removed \n",
      "\n",
      "5. feature name: FG%\n",
      "8. feature name: 3P%\n",
      "11. feature name: FT%\n",
      "\n",
      "Feature selection: None\n",
      "Accuracy: 0.89 (+/- 0.06)\n",
      "Number of features left: 24\n",
      "\n",
      "Feature selection: Domain\n",
      "Accuracy: 0.90 (+/- 0.06)\n",
      "Number of features left: 13\n",
      "\n",
      "Feature selection: Univariate\n",
      "Accuracy: 0.89 (+/- 0.06)\n",
      "Number of features left: 5\n",
      "\n",
      "Feature selection: Variance Threshold\n",
      "Accuracy: 0.90 (+/- 0.05)\n",
      "Number of features left: 21\n"
     ]
    }
   ],
   "source": [
    "logreg = linear_model.LogisticRegression(C=1e5)\n",
    "clf_all(logreg, features, labels, domain)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
